<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/Academy-favicon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/Academy-favicon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/Academy-favicon.png">
  <link rel="mask-icon" href="/images/Academy-favicon" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="next-config" data-name="main" type="application/json">{&quot;hostname&quot;:&quot;zhang-xiaoxue.github.io&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Muse&quot;,&quot;version&quot;:&quot;8.4.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;right&quot;,&quot;display&quot;:&quot;post&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:false,&quot;bookmark&quot;:{&quot;enable&quot;:false,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:false,&quot;mediumzoom&quot;:false,&quot;lazyload&quot;:false,&quot;pangu&quot;:false,&quot;comments&quot;:{&quot;style&quot;:&quot;tabs&quot;,&quot;active&quot;:null,&quot;storage&quot;:true,&quot;lazyload&quot;:false,&quot;nav&quot;:null},&quot;motion&quot;:{&quot;enable&quot;:true,&quot;async&quot;:false,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;Searching...&quot;,&quot;empty&quot;:&quot;We didn&#39;t find any results for the search: ${query}&quot;,&quot;hits_time&quot;:&quot;${hits} results found in ${time} ms&quot;,&quot;hits&quot;:&quot;${hits} results found&quot;}}</script>
<meta name="description" content="3. Convex Analysis3.1 Prove convex set: $x,y\in C$, then prove $\lambda x + (1-\lambda y) \in C$ intersection of convex sets are convex $f$ is convex  $\iff$  epigraph set is convex $f(x)\le \alpha$">
<meta property="og:type" content="article">
<meta property="og:title" content="3. Convex Analysis">
<meta property="og:url" content="https://zhang-xiaoxue.github.io/2021/08/16/Nonlinear%20Optimization/0_Supplementary/index.html">
<meta property="og:site_name" content="Xiaoxue Zhang - NUS">
<meta property="og:description" content="3. Convex Analysis3.1 Prove convex set: $x,y\in C$, then prove $\lambda x + (1-\lambda y) \in C$ intersection of convex sets are convex $f$ is convex  $\iff$  epigraph set is convex $f(x)\le \alpha$">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8iaab2yg8j31ae0kqwjo.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8iaoz35m8j316u0qg7b3.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ibxikl2ij30gk05674m.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8iby7vro4j30ju030q35.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/Lisnol1/PicGo--/master/20191031234729.png">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ialuccwmj31b0070gmo.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8iamsirn8j30u00wajzd.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/Lisnol1/PicGo--/master/20191031183333.png">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8iauh86t5j313m0ak0uu.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8iavh73xej313j0u0q8k.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ibfziambj312j0u0tgd.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ibpeyfj2j31800u0gv5.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ic4fs783j31f20esmzw.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ic3knxdvj31e00ay0va.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8icadeavgj31f60b8wfs.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8iciivhccj31dc0u044k.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8icbl7sasj31es0b8q5k.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ice24l9uj31fc0cm0v3.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8icf6y0ktj30wv0u0ahy.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8icg6z4mnj31eo0aa763.jpg">
<meta property="og:image" content="https://raw.githubusercontent.com/Lisnol1/PicGo--/master/20191031184341.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Lisnol1/PicGo--/master/20191031184559.png">
<meta property="article:published_time" content="2021-08-16T04:00:00.000Z">
<meta property="article:modified_time" content="2021-08-16T06:59:49.598Z">
<meta property="article:author" content="Xiaoxue Zhang">
<meta property="article:tag" content="Reinforcement Learning, Optimization and Control, Intellegent Systems">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8iaab2yg8j31ae0kqwjo.jpg">


<link rel="canonical" href="https://zhang-xiaoxue.github.io/2021/08/16/Nonlinear%20Optimization/0_Supplementary/">



<script class="next-config" data-name="page" type="application/json">{&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:false,&quot;isPost&quot;:true,&quot;lang&quot;:&quot;en&quot;,&quot;comments&quot;:true,&quot;permalink&quot;:&quot;https:&#x2F;&#x2F;zhang-xiaoxue.github.io&#x2F;2021&#x2F;08&#x2F;16&#x2F;Nonlinear%20Optimization&#x2F;0_Supplementary&#x2F;&quot;,&quot;path&quot;:&quot;2021&#x2F;08&#x2F;16&#x2F;Nonlinear Optimization&#x2F;0_Supplementary&#x2F;&quot;,&quot;title&quot;:&quot;3. Convex Analysis&quot;}</script>

<script class="next-config" data-name="calendar" type="application/json">&quot;&quot;</script>
<title>3. Convex Analysis | Xiaoxue Zhang - NUS</title><script src="/js/config.js"></script>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Xiaoxue Zhang - NUS</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">NUS Ph.D.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#3-Convex-Analysis"><span class="nav-number">1.</span> <span class="nav-text">3. Convex Analysis</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-Prove-convex-set"><span class="nav-number">1.1.</span> <span class="nav-text">3.1 Prove convex set:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-Prove-convex-function"><span class="nav-number">1.2.</span> <span class="nav-text">3.2 Prove convex function:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-Projection-Pi-C-z-mathrm-argmin-frac-1-2-x-z-2-vert-x-in-C"><span class="nav-number">1.3.</span> <span class="nav-text">3.3 Projection: $\Pi_C(z) &#x3D; \mathrm{argmin} { \frac{1}{2} |x-z|^2 \vert x\in C }$</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-4-Cones"><span class="nav-number">1.4.</span> <span class="nav-text">3.4 Cones:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-5-Subgradient"><span class="nav-number">1.5.</span> <span class="nav-text">3.5 Subgradient:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-6-Frenchel-Conjugate"><span class="nav-number">1.6.</span> <span class="nav-text">3.6 Frenchel Conjugate:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-7-Moreau-Yosida-regularization-and-proximal-mapping"><span class="nav-number">1.7.</span> <span class="nav-text">3.7 Moreau-Yosida regularization and proximal mapping</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-Gradient-Methods"><span class="nav-number">2.</span> <span class="nav-text">4. Gradient Methods</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-Basic-NLP-KKT"><span class="nav-number">3.</span> <span class="nav-text">5. Basic NLP (KKT)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6-Lagrangian-duality"><span class="nav-number">4.</span> <span class="nav-text">6. Lagrangian duality</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#7-Nonlinear-conic-programming"><span class="nav-number">5.</span> <span class="nav-text">7. Nonlinear conic programming</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Sparse-regression-problem"><span class="nav-number">6.</span> <span class="nav-text">Sparse regression problem:</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Indicator-function"><span class="nav-number">6.1.</span> <span class="nav-text">Indicator function:</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Dual-problems"><span class="nav-number">7.</span> <span class="nav-text">Dual problems:</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Xiaoxue Zhang"
      src="/images/photo_blue.jpg">
  <p class="site-author-name" itemprop="name">Xiaoxue Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">27</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/Zhang-Xiaoxue" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Zhang-Xiaoxue" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:xiaoxuezhang@u.nus.edu" title="E-Mail → mailto:xiaoxuezhang@u.nus.edu" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.linkedin.com/in/xiaoxue-zhang-5233b611a/" title="https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;xiaoxue-zhang-5233b611a&#x2F;" rel="noopener" target="_blank">Linkedin</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.zhihu.com/people/lisnol" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;lisnol" rel="noopener" target="_blank">知乎</a>
        </li>
    </ul>
  </div>

        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/Zhang-Xiaoxue" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhang-xiaoxue.github.io/2021/08/16/Nonlinear%20Optimization/0_Supplementary/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/photo_blue.jpg">
      <meta itemprop="name" content="Xiaoxue Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiaoxue Zhang - NUS">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          3. Convex Analysis
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2021-08-16 12:00:00 / Modified: 14:59:49" itemprop="dateCreated datePublished" datetime="2021-08-16T12:00:00+08:00">2021-08-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Nonlinear-Optimization/" itemprop="url" rel="index"><span itemprop="name">Nonlinear Optimization</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="3-Convex-Analysis"><a href="#3-Convex-Analysis" class="headerlink" title="3. Convex Analysis"></a>3. Convex Analysis</h1><h2 id="3-1-Prove-convex-set"><a href="#3-1-Prove-convex-set" class="headerlink" title="3.1 Prove convex set:"></a><strong>3.1 Prove convex set:</strong></h2><ol>
<li>$x,y\in C$, then prove $\lambda x + (1-\lambda y) \in C$</li>
<li>intersection of convex sets are convex</li>
<li>$f$ is convex  $\iff$  epigraph set is convex $f(x)\le \alpha$</li>
</ol>
<h2 id="3-2-Prove-convex-function"><a href="#3-2-Prove-convex-function" class="headerlink" title="3.2 Prove convex function:"></a><strong>3.2 Prove convex function:</strong></h2><ol>
<li>Prove $f(\lambda x + (1-\lambda)y) \le \lambda f(x) + (1-\lambda) y$</li>
<li>(sum of) linear combination of convex function is convex</li>
<li>$h$ convex, $g$ non-decreasing convex, $g\circ h$ is convex</li>
<li>epigraph set is convex $f(x)\le \alpha$ $\iff$ $f$ is convex </li>
<li>convex, then $x=\sum_{k=1}^k \lambda_jx^{j}$, where $\sum_{j=1}^k \lambda_j =1$, we have $f(x)\le \sum_{k=1}^k \lambda_j f(x^j)$ <strong>Jensen’s inequality:</strong> </li>
<li>convex $\iff$   $f(y) \le f(x)+\nabla f(x)^T (y-x)$ <strong>Tangent plane characterization:</strong> </li>
<li>convex $\iff$  $\langle \nabla f(\mathbb y)-\nabla f(\mathbb x), \mathbb y - \mathbb x \rangle \ge 0, \quad \forall \mathbb x, \mathbb y \in S$   monotone gradient condition</li>
<li>convex $\iff$  Hessian is positive semidefinite</li>
</ol>
<p>For constrained convex programming $\min{f(x)|x\in C}$, $x^*$ is global minimizer $\iff$ $\langle \triangledown f(x^*), x-x^* \rangle &gt; 0, \forall x \in C$.</p>
<h2 id="3-3-Projection-Pi-C-z-mathrm-argmin-frac-1-2-x-z-2-vert-x-in-C"><a href="#3-3-Projection-Pi-C-z-mathrm-argmin-frac-1-2-x-z-2-vert-x-in-C" class="headerlink" title="3.3 Projection: $\Pi_C(z) = \mathrm{argmin} { \frac{1}{2} |x-z|^2 \vert x\in C }$"></a><strong>3.3 Projection:</strong> $\Pi_C(z) = \mathrm{argmin} { \frac{1}{2} |x-z|^2 \vert x\in C }$</h2><ul>
<li>$x^* = \Pi_C(z)$  $\iff$  $\langle z-x^*, x-x^* \rangle \leq 0, \forall x\in C$</li>
<li>$| \Pi_C(z) - \Pi_C(w) | \leq |z-w |$. </li>
</ul>
<blockquote>
<ul>
<li>C is linear subspace, $z-x^*\perp C$, then $z = \Pi_C(z) + (z-\Pi_C(z)), \quad \text{and } \quad \langle z-\Pi_C(z), \Pi_C(z)\rangle = 0$</li>
<li>C is closed convex cone, $\langle z-\Pi_C(z), \Pi_C(z)\rangle = 0$</li>
<li>If $\theta (x) = \frac{1}{2} | x-\Pi_C(x)|^2$, then $\theta(\cdot)$ is a continuously differentiable convex function and $\nabla \theta(x) = x-\Pi_C(x)$</li>
</ul>
</blockquote>
<h2 id="3-4-Cones"><a href="#3-4-Cones" class="headerlink" title="3.4 Cones:"></a><strong>3.4 Cones:</strong></h2><ul>
<li>Dual cone: $S^* = { y\in S | \langle x,y \rangle \ge 0, \forall x\in S }$. Self-dual cone $C^*=C$, including $\mathbb S_+^n$, $\mathbb R^n$,</li>
<li>Polar cone: $S^\circ = -S^*$</li>
<li>$(C^*)^*=C$.</li>
<li>Spectral cone $\mathcal K^*$, Nuclear-norm cone $\mathcal C$, $\mathrm {COP}_n$, $\mathrm {CPP}_n$, double nonnegative cone $\mathbb D_n$. [Chapter 3, P79]</li>
<li>$z-\Pi_C(z) = \Pi_{C^\circ}(z)$, if $C$ is closed convex cone.</li>
<li><strong>Normal cone</strong>:<ul>
<li> $N_C(\bar x) = {z\in \mathcal E | \langle z, x-\bar x \rangle \leq 0, \forall x\in C}$ where $\bar x \in C$.</li>
<li>$u\in N_C(y) \iff y=\Pi_C(y+u)$</li>
<li>$N_{C_1} (\bar x) + N_{C_2} (\bar x) \subset N_{C_1\cap C_2} (\bar x)$ where $\bar x \in C_1 \cap C_2$.</li>
<li>$C=\mathcal S^n_+$. $X=U_1D_1U_1^T, D_1 = \mathrm{diag}(d_1, \cdots, d_r)$ with descending order. $N_C(X)={-U_2\Delta U_2^T}$. [P81]</li>
</ul>
</li>
</ul>
<h2 id="3-5-Subgradient"><a href="#3-5-Subgradient" class="headerlink" title="3.5 Subgradient:"></a><strong>3.5 Subgradient:</strong></h2><ul>
<li><p>$\langle v-u, y-x \rangle \ge 0, \quad \forall u\in \part f(x), v\in \part f(y)$   Monotone mapping</p>
</li>
<li><p>$\part \delta_C(x) = \begin{cases}<br>\empty \quad &amp; \text{if }x\notin C \<br>\mathcal N_C(x)= \text{normal cone of $C$ at $x$} \quad &amp; \text{if }x\in C<br>\end{cases}$  where $C$ is convex subset of $\mathbb R^n$</p>
</li>
<li><p>$\part f(0) = { y\in \mathbb R^n | |y|_\infty \le 1 }$, if $f(x) = | x |_1$   [P85]</p>
</li>
</ul>
<h2 id="3-6-Frenchel-Conjugate"><a href="#3-6-Frenchel-Conjugate" class="headerlink" title="3.6 Frenchel Conjugate:"></a>3.6 Frenchel Conjugate:</h2><p>$$<br>f^*(y) = \sup { \langle y,x \rangle - f(x) | x\in \mathcal E }, y\in \mathcal \ E<br>$$</p>
<ul>
<li><p>$f^*$ is always closed and convex, even if $f$ is non-convex or not closed.</p>
</li>
<li><p>Equivalent condition</p>
<ol>
<li>$f(x) + f^*(x^*) = \langle x, x^* \rangle$</li>
<li>$x^* \in \part f(x)$</li>
<li>$x \in \part f^*(x^*)$</li>
<li>$\langle x, x^* \rangle - f(x) =\max_{z\in \mathcal E} {\langle z, x^* \rangle - f(z)}$</li>
<li>$\langle x, x^* \rangle - f^*(x^*) =\max_{z^<em>\in \mathcal E} {\langle x, z^</em> \rangle - f^*(z^*)}$</li>
<li>$(f^*)^* = f$</li>
</ol>
</li>
</ul>
<h2 id="3-7-Moreau-Yosida-regularization-and-proximal-mapping"><a href="#3-7-Moreau-Yosida-regularization-and-proximal-mapping" class="headerlink" title="3.7 Moreau-Yosida regularization and proximal mapping"></a>3.7 Moreau-Yosida regularization and proximal mapping</h2><p>$$<br>\begin{array}{ll}{\text { MY regularization of } f \text { at } x:} &amp; {M_{f}(x)=\min <em>{y \in \mathcal{E}}\left{\phi(y ; x):=f(y)+\frac{1}{2}|y-x|^{2}\right}} \ {\text { Proximal mapping } f \text { at } x:} &amp; {P</em>{f}(x)=\operatorname{argmin}_{y \in \mathcal{E}}{\phi(y ; x):=f(y)+\frac{1}{2}|y-x|^{2}}}\end{array}<br>$$</p>
<ul>
<li> $x=P_f(x)+P_{f^*}(x), \forall x\in \mathcal E$</li>
<li>$f(x)=\lambda |x|_1$, $f^*(z)=\delta_C(z)$ where $C=\part f(0)={z\in \mathbb R^n | |z|_\infty \le \lambda }$   [P91]</li>
<li> If  $f=\delta_C$, $P_{\delta_{C}}(x)=\operatorname{argmin}<em>{y \in \mathcal{E}}\left{\delta</em>{C}(y)+\frac{1}{2}|y-x|\right}=\operatorname{argmin}<em>{y \in C} \frac{1}{2}|y-x|^{2}=\Pi</em>{C}(x)$.  [P92]</li>
<li>if $C=\mathbb S_+^n$, Then $\Pi_C(x)=Q\mathrm{diag}d_+ Q^T \quad \text{using spectral decomposition } x=Q \mathrm{diag}dQ^T$ </li>
</ul>
<h1 id="4-Gradient-Methods"><a href="#4-Gradient-Methods" class="headerlink" title="4. Gradient Methods"></a>4. Gradient Methods</h1><p>Descent direction: direction $\mathbf d$ such that $\langle \nabla f(x^*), d\rangle &lt;0 $.</p>
<p>Steepest decent direction: direction $\mathbf d$ such that $\mathbf d^* = - \nabla f(x^*)$.</p>
<ol>
<li><p><strong>Steepest descent method with exact line search:</strong> + Convergence rate</p>
</li>
<li><p><strong>Accelerated Proximal Gradient method:</strong> + Error, complexity </p>
<ol>
<li>Sparse regression [P112]</li>
<li><u>Projection on to convex cone</u> $\mathrm{DNN}<em>n^* = \mathbb S</em>+^n + \mathcal N^n$  [P112]</li>
</ol>
</li>
<li><p>Gradient Projection Method:</p>
<p>$x^{k+1} = P_Q(x^k - \alpha_k \nabla f(x^k))$, where $x(\alpha) = x-\alpha \nabla f(x)$, $x_Q(\alpha) = P_!(x(\alpha))$</p>
</li>
<li><p>Stochastic Gradient Descent Method</p>
</li>
</ol>
<h1 id="5-Basic-NLP-KKT"><a href="#5-Basic-NLP-KKT" class="headerlink" title="5. Basic NLP (KKT)"></a>5. Basic NLP (KKT)</h1><p>(LICQ): Linear Independency Constraint Qualification : regular point : $\nabla h_i$ and $\nabla g_i$ are linear independent.</p>
<p><strong>KKT necessary condition:</strong> </p>
<ul>
<li><p>1st order:</p>
<p> $\begin{array}{l}{[1] \quad \nabla f\left(\mathrm{x}^{<em>}\right)+\sum_{i=1}^{m} \lambda_{i}^{</em>} \nabla g_{i}\left(\mathrm{x}^{<em>}\right)+\sum_{j=1}^{p} \mu_{j}^{</em>} \nabla h_{j}\left(\mathrm{x}^{<em>}\right)=0} \ {[2] \quad g_{i}\left(\mathrm{x}^{</em>}\right)=0, \quad \forall i=1,2, \cdots, m} \ {[3] \quad \mu_{j}^{<em>} \geq 0, h_{j}\left(\mathrm{x}^{</em>}\right) \leq 0, \quad \mu_{j}^{<em>} h_{j}\left(\mathrm{x}^{</em>}\right)=0, \quad \forall j=1,2, \cdots, p}\end{array}$</p>
</li>
<li><p>2nd order: $y^T H_L(x^*) y \ge 0$ where $y\in T(x^*)$ tangent plane</p>
<ul>
<li>Easier check: $Z(x^*)H_L(x^*)Z(x^*)$ is positive semidefinite</li>
</ul>
</li>
</ul>
<p><strong>Steps:</strong></p>
<ol>
<li>Check regularity condition</li>
<li>verify KKT first order necessary condition.</li>
<li>verify KKT second order necessary condition<ol>
<li>Hessian matrix</li>
<li>basis of null space of $\mathcal D(\mathbb x^*)^T$</li>
<li>definiteness check</li>
</ol>
</li>
</ol>
<p><strong>Projection onto simplex:</strong> [P139-140]</p>
<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8iaab2yg8j31ae0kqwjo.jpg" style="zoom: 45%">

<p><em>relax multipliers</em></p>
<p><strong>KKT sufficient conditions</strong>: 1st + 2nd</p>
<p><strong>steps:</strong></p>
<ol>
<li>verify it’s KKT point. </li>
<li>verify it satisfy the second order sufficient condition<ol>
<li>Hessian matrix</li>
<li>$Z(\mathbf x^*)$</li>
<li>Determine definiteness</li>
</ol>
</li>
</ol>
<p><strong>Important points:</strong></p>
<ol>
<li><p><u><strong>KKT point is an optimal solution under convexity</strong></u>, <strong>but a global minimizer of a convex program may not be a KKT point.</strong></p>
</li>
<li><p><strong><u>With regularity condition</u></strong>, a global minimizer is a KKT point. For convex programming problem with at least one inequality constraints, the Slater’s condition ensures that a global minimizer is a KKT point.</p>
<p><strong><u>slater’s condition</u>:</strong> there exists $\hat{\mathbb x} ∈ \mathbb R^n$ such that $g_i(\hat{\mathbb x}) = 0, ∀ i = 1,\cdots, m$ and $h_j(\hat{\mathbb x}) &lt; 0, ∀ j = 1, . . . , p$.</p>
<pre><code> Slater&#39;s condition states that the feasible region must have an [interior point](https://en.wikipedia.org/wiki/Interior_(topology)).
</code></pre>
</li>
<li><p>Linear equality constrained problem: </p>
<p>a point $x^∗ ∈ S$ is a KKT point $\iff$  $x^∗$ is a global minimizer of $f$ on $S$.</p>
<p>No regularity or slater condition is needed.</p>
</li>
<li><p>LInear + convex quadratic programming.</p>
</li>
</ol>
<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8iaoz35m8j316u0qg7b3.jpg" style="zoom:40%">

<h1 id="6-Lagrangian-duality"><a href="#6-Lagrangian-duality" class="headerlink" title="6. Lagrangian duality"></a>6. Lagrangian duality</h1><p><u>optimal value of dual problem is smaller than optimal value of primal problem.</u>  Duality gap;</p>
<p><strong>Saddle point optimality $\longleftrightarrow$ KKT</strong></p>
<ol>
<li>For a fixed $\mathbb x^∗$, $(λ^∗, μ^∗)$ maximizes $L(\mathbb x^∗, λ, μ)$ over all $(λ, μ)$ with $μ ≥ 0$.</li>
<li>For a fixed $(λ^∗, μ^∗)$ , $\mathbb{x}^*$ minimizes $L(\mathbb x, λ^∗, μ^∗)$ over all $x ∈ X$.</li>
<li>saddle point $(\mathbb x^*, \lambda^*,\mu^*)$ $\Rightarrow$ KKT condition. but inverse is not true in general.</li>
<li>KKT point of a convex program is a saddle point.</li>
</ol>
<h1 id="7-Nonlinear-conic-programming"><a href="#7-Nonlinear-conic-programming" class="headerlink" title="7. Nonlinear conic programming"></a>7. Nonlinear conic programming</h1><p>​                        <img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ibxikl2ij30gk05674m.jpg" style="zoom:40%">         <img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8iby7vro4j30ju030q35.jpg" style="zoom: 40%"></p>
<h1 id="Sparse-regression-problem"><a href="#Sparse-regression-problem" class="headerlink" title="Sparse regression problem:"></a>Sparse regression problem:</h1><ul>
<li><p>objective function is convex</p>
</li>
<li><p>APG: [P112]</p>
<img src="https://raw.githubusercontent.com/Lisnol1/PicGo--/master/20191031234729.png" style="zoom:35%"></li>
<li><p>KKT: [P153-154]</p>
<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ialuccwmj31b0070gmo.jpg" style="zoom: 32%">

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8iamsirn8j30u00wajzd.jpg" style="zoom:50%"></li>
</ul>
<ol start="2">
<li><p>Chapter 7. conic programming</p>
</li>
<li><p>Chapter 8. sPADMM</p>
<p>P214</p>
</li>
<li></li>
</ol>
<img src="https://raw.githubusercontent.com/Lisnol1/PicGo--/master/20191031183333.png" style="zoom: 60%">



<h2 id="Indicator-function"><a href="#Indicator-function" class="headerlink" title="Indicator function:"></a>Indicator function:</h2><ul>
<li>Indicator function: $\delta_C(x) = \begin{cases} 0, &amp; x\in C \ \infty, &amp; x\notin C \end{cases}$</li>
</ul>
<p>$$<br>\delta_{S_+^n}^* = \delta_{-S_+^n}<br>$$</p>
<p>$$<br>\mathrm{Prof}_f(x) = (I+\lambda \part f)^{-1}<br>$$</p>
<p>$P_f(x) = x-P_{f^*}(x)$</p>
<p>Proximal $P_f$ and Projection $\Pi_C(f(x))$ : When $f=\delta$ indicator function, the two operator are equivalent.</p>
<p> $f(x) = \lambda |x|_1 $,  then $f^*(z) = \delta_C(z)$ where $C=\part f(0) = {z\in\mathbb R^n | |z|_\infty \le \lambda }$, the proximal function $P_f(x) = \mathrm {sgn} (x) \circ \max{|x|-\lambda }$  [P91-92]</p>
<p>$f=\delta_C$, $C$ is closed and convex, the proximal and projection operator are equivalent, because $P_{\delta_{C}}(x)=\operatorname{argmin}<em>{y \in \mathcal{E}}\left{\delta</em>{C}(y)+\frac{1}{2}|y-x|\right}=\operatorname{argmin}<em>{y \in C} \frac{1}{2}|y-x|^{2}=\Pi</em>{C}(x)$. When $C=\mathbb S_+^n$, then $\Pi_C(x)=Q \mathrm {diag}(d_+) Q^T$ using spectral decomposition $x=Q\mathrm {diag}(d) Q^T$</p>
<p>$f(x)=|x|_*$, then the $P_f(x) = V\Sigma^+ U^T$.</p>
<p>$x^* = P_f(x^*)$ will converge to the optimum of $f$, i.e., $x^*$. </p>
<p>Dual norm: [P88]</p>
<ul>
<li>$f(x)=\lambda |x|<em>1$, then $f^*(x) = \delta</em>{B_\lambda}$, where $B_\lambda = {x\in \mathbb R^n | |x|_\infty\leq \lambda}$. </li>
<li>$f(x)=\lambda |x|<em>\infty$, then $f^*(x) = \delta</em>{B_\lambda}$, where $B_\lambda = {x\in \mathbb R^n | |x|_1\leq \lambda}$. </li>
<li>$f(x)=\lambda |x|<em>m$, then $f^*(x) = \delta</em>{B_\lambda}$, where $B_\lambda = {x\in \mathbb R^n | |x|_n\leq \lambda}$, $\frac{1}{m}+\frac{1}{n}=1$, called dual norm. </li>
<li>$\ell_2$ norm is self-dual norm. </li>
</ul>
<p>$y\in N_C(x)$, then $y\in \Pi_C(x+y)$</p>
<p>$x=P_f(x)+P_{f^*}(x), \forall x\in \mathcal E$</p>
<p>$G = \Pi_{\mathbb S_+^*}(G) - \Pi_{\mathbb S_+^n}(-G)$</p>
<p>$\min{ \frac{1}{2}|G+Z|^2 | Z\in \mathbb S_+^n} = \frac{1}{2} | G+\Pi_{\mathbb S^n_+}(G)|^2 = \frac{1}{2} |\Pi_{\mathbb S_+^n}(G) |^2$</p>
<ol>
<li>$\mathbb x \in S \iff \mathbb x = \mathbb x^* + \mathbb z$ for some $\mathbb z \in \operatorname{Null}(A)$.  【space of x】</li>
<li>$\mathbb y^T \mathbb z = 0$, $\forall \mathbb z \in \operatorname{Null}(\mathbf A) \iff \exist \lambda^* \in \mathbb R^m$ s.t. $\mathbb y+ \mathbf A^T \lambda^*=0$.</li>
</ol>
<p>The linear map $\mathcal A(X) = \begin{bmatrix} \langle A_1, X \rangle \ \vdots \  \langle A_m, X \rangle  \end{bmatrix}$. Let $\mathcal A^* $ be adjoint of $\mathcal A$ as $\mathcal A^* y = \sum\limits_{k=1}^m y_kA_k, y\in \mathbb R^m$.<br>$$<br>\langle \mathcal A^* y, X \rangle = \langle y, \mathcal A X \rangle<br>$$<br>if $\mathcal A(X) = \operatorname{diag} (X)$, then $A_k = E_{kk}$, and $\mathcal A^* y =  \operatorname{diag} (y)$.</p>
<h1 id="Dual-problems"><a href="#Dual-problems" class="headerlink" title="Dual problems:"></a>Dual problems:</h1><ul>
<li><p><strong>Linear programs + dual problem:</strong></p>
<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8iauh86t5j313m0ak0uu.jpg" style="zoom: 40%">

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8iavh73xej313j0u0q8k.jpg" style="zoom:40%"></li>
<li><p><strong>Quadratic program + dual problem</strong></p>
<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ibfziambj312j0u0tgd.jpg" style="zoom:40%"></li>
<li><p><strong>Square function + Linear inequality constraints  [P177]</strong></p>
<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ibpeyfj2j31800u0gv5.jpg" style="zoom:40%"></li>
<li><p><strong>NLP + dual problem [P178,180]</strong></p>
<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ic4fs783j31f20esmzw.jpg" style="zoom:39%">

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ic3knxdvj31e00ay0va.jpg" style="zoom: 40%"></li>
<li><p><strong>SDP + Dual Problem [P178, P180]</strong></p>
<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8icadeavgj31f60b8wfs.jpg" style="zoom:38.5%">

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8iciivhccj31dc0u044k.jpg" style="zoom:40%"></li>
<li><p><strong>SDPLS + dual problem [P179, ]</strong></p>
<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8icbl7sasj31es0b8q5k.jpg" style="zoom: 38%">

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ice24l9uj31fc0cm0v3.jpg" style="zoom:37.5%">

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8icf6y0ktj30wv0u0ahy.jpg" style="zoom:57%">

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8icg6z4mnj31eo0aa763.jpg" style="zoom:37%"></li>
<li><p><strong>Quadratic Semidefinite problem + Dual problem</strong></p>
<img src="https://raw.githubusercontent.com/Lisnol1/PicGo--/master/20191031184341.png" style="zoom: 60%"></li>
<li><p><strong>Convex quadratic composite optimization problem + dual problem:</strong></p>
<img src="https://raw.githubusercontent.com/Lisnol1/PicGo--/master/20191031184559.png" style="zoom:60%"></li>
<li><p>d</p>
</li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>Post author:  </strong>Xiaoxue Zhang
  </li>
  <li class="post-copyright-link">
      <strong>Post link: </strong>
      <a href="https://zhang-xiaoxue.github.io/2021/08/16/Nonlinear%20Optimization/0_Supplementary/" title="3. Convex Analysis">https://zhang-xiaoxue.github.io/2021/08/16/Nonlinear Optimization/0_Supplementary/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> unless stating additionally.
  </li>
</ul>
</div>


        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/08/16/Nonlinear%20Optimization/2_Introduction/" rel="prev" title="2. Introduction">
                  <i class="fa fa-chevron-left"></i> 2. Introduction
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>





<script src="/js/comments.js"></script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Xiaoxue Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div><script color="0,0,255" opacity="0.5" zIndex="-1" count="199" src="https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js"></script>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{&quot;enable&quot;:true,&quot;tags&quot;:&quot;none&quot;,&quot;single_dollars&quot;:true,&quot;cjk_width&quot;:0.9,&quot;normal_width&quot;:0.6,&quot;append_css&quot;:true,&quot;js&quot;:&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;mathjax@3.1.4&#x2F;es5&#x2F;tex-mml-chtml.js&quot;}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
