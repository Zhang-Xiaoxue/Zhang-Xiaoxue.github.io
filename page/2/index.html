<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/Academy-favicon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/Academy-favicon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/Academy-favicon.png">
  <link rel="mask-icon" href="/images/Academy-favicon" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="next-config" data-name="main" type="application/json">{&quot;hostname&quot;:&quot;zhang-xiaoxue.github.io&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Muse&quot;,&quot;version&quot;:&quot;8.4.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;right&quot;,&quot;display&quot;:&quot;post&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:false,&quot;bookmark&quot;:{&quot;enable&quot;:false,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:false,&quot;mediumzoom&quot;:false,&quot;lazyload&quot;:false,&quot;pangu&quot;:false,&quot;comments&quot;:{&quot;style&quot;:&quot;tabs&quot;,&quot;active&quot;:null,&quot;storage&quot;:true,&quot;lazyload&quot;:false,&quot;nav&quot;:null},&quot;motion&quot;:{&quot;enable&quot;:true,&quot;async&quot;:false,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;Searching...&quot;,&quot;empty&quot;:&quot;We didn&#39;t find any results for the search: ${query}&quot;,&quot;hits_time&quot;:&quot;${hits} results found in ${time} ms&quot;,&quot;hits&quot;:&quot;${hits} results found&quot;}}</script>
<meta property="og:type" content="website">
<meta property="og:title" content="Xiaoxue Zhang - NUS">
<meta property="og:url" content="https://zhang-xiaoxue.github.io/page/2/index.html">
<meta property="og:site_name" content="Xiaoxue Zhang - NUS">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Xiaoxue Zhang">
<meta property="article:tag" content="Reinforcement Learning, Optimization and Control, Intellegent Systems">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://zhang-xiaoxue.github.io/page/2/">



<script class="next-config" data-name="page" type="application/json">{&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:true,&quot;isPost&quot;:false,&quot;lang&quot;:&quot;en&quot;,&quot;comments&quot;:&quot;&quot;,&quot;permalink&quot;:&quot;&quot;,&quot;path&quot;:&quot;page&#x2F;2&#x2F;index.html&quot;,&quot;title&quot;:&quot;&quot;}</script>

<script class="next-config" data-name="calendar" type="application/json">&quot;&quot;</script>
<title>Xiaoxue Zhang - NUS</title><script src="/js/config.js"></script>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Xiaoxue Zhang - NUS</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">NUS Ph.D.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Xiaoxue Zhang"
      src="/images/photo_blue.jpg">
  <p class="site-author-name" itemprop="name">Xiaoxue Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">27</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/Zhang-Xiaoxue" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Zhang-Xiaoxue" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:xiaoxuezhang@u.nus.edu" title="E-Mail → mailto:xiaoxuezhang@u.nus.edu" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.linkedin.com/in/xiaoxue-zhang-5233b611a/" title="https:&#x2F;&#x2F;www.linkedin.com&#x2F;in&#x2F;xiaoxue-zhang-5233b611a&#x2F;" rel="noopener" target="_blank">Linkedin</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.zhihu.com/people/lisnol" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;lisnol" rel="noopener" target="_blank">知乎</a>
        </li>
    </ul>
  </div>

        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/Zhang-Xiaoxue" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhang-xiaoxue.github.io/2020/07/30/Model%20Predictive%20Control/MPC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/photo_blue.jpg">
      <meta itemprop="name" content="Xiaoxue Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiaoxue Zhang - NUS">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/07/30/Model%20Predictive%20Control/MPC/" class="post-title-link" itemprop="url">Model Predictive Control (MPC)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-07-30 12:00:00" itemprop="dateCreated datePublished" datetime="2020-07-30T12:00:00+08:00">2020-07-30</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2021-08-16 15:17:17" itemprop="dateModified" datetime="2021-08-16T15:17:17+08:00">2021-08-16</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Model-Predictive-Control/" itemprop="url" rel="index"><span itemprop="name">Model Predictive Control</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="MPC"><a href="#MPC" class="headerlink" title="MPC"></a>MPC</h1><p>Linear MPC requires solving a Quadratic Program (QP)</p>
<p>$\min\limits_{z} \ \frac{1}{2} z’Hz+x(t)’F’z + \frac{1}{2}x’(t)Yx(t)$</p>
<p>s.t. $Gz\le W+Sx$</p>
<p>where  $z=\begin{bmatrix} u_0 \ u_1 \ \vdots \ u_{N-1} \end{bmatrix}$</p>
<p>These define a polyhedron where the solution should lie.</p>
<h2 id="QP-solver"><a href="#QP-solver" class="headerlink" title="QP solver"></a>QP solver</h2><h3 id="fast-gradient-method-for-dual-QP"><a href="#fast-gradient-method-for-dual-QP" class="headerlink" title="fast gradient method for dual QP"></a>fast gradient method for dual QP</h3><ul>
<li><p>apply fast gradient method to dual QP</p>
<p>​    $\min\limits_{z} \ \frac{1}{2} z’Hz+x’F’z$</p>
<p>​    s.t. $Gz\le W+Sx$    </p>
<p>Example:</p>
<p>Model:</p>
<p>​    $\begin{align} w_k &amp;= y_k+\beta_k(y_k - y_{k-1})\ z_k &amp;= -Kw_k-Jx\  s_k &amp;= \frac{1}{L}Gz_k-\frac{1}{L}(Sx+W)\  y_{k+1} &amp;= \max { y_k+s_k, 0 }\end{align}$  </p>
<p>​    Where $y_{-1}=y_0=0$, $K = H^{-1}G’$ , and $J=H^{-1}F’$, $\beta=\begin{cases}0,\quad k=0\ \frac{k_1}{k+2},\quad k&gt;0 \end{cases}$ </p>
<p>Termination criterion:</p>
<ol>
<li><p>primal feasibility</p>
<p>$s_k^i \leq \frac{1}{L}\epsilon_G,\quad \forall i =1,\cdots, m$</p>
</li>
<li><p>primal oprimality </p>
<p>$f(z_k)-f^*\leq f(z_k)-\phi(w_k)=-w’_ks_kL\leq\epsilon_V$ </p>
<p>and $-w’_k s_k \leq \frac{1}{L} \epsilon_V$</p>
</li>
</ol>
</li>
</ul>
<h2 id="solve-MPC"><a href="#solve-MPC" class="headerlink" title="solve MPC:"></a>solve MPC:</h2><p>Step 1:  get a linear discrete-time model </p>
<p>system linearization</p>
<p>Step 2: design the MPC controller</p>
<h1 id="LPV"><a href="#LPV" class="headerlink" title="LPV"></a>LPV</h1><p><strong>LinearParameter-Varying(LPV)</strong> model</p>
<p>​    $$\begin{align} x_{k+1}&amp;=A(p(t))x_k+B(p(t))u_k+B_v(p(t))v_k \ y_{k+1}&amp;=C(p(t))x_k+D_v(p(t))v_k \end{align}$$</p>
<p>​    depends on $p(t)$ </p>
<p>the quadratic perfirmance index can also be LPV, and the resulting optimization problem is still a QP:</p>
<p>​    $$\begin{align} \min\limits_{z}\quad \frac{1}{2} z’H(p(t))z+\begin{bmatrix} x(t)\ r(t)\ u(t-1) \end{bmatrix}’ F(p(t))’ z’ \ \text{s.t.} \quad G(p(t))z \leq W(p(t))+S(p(t))\begin{bmatrix} x(t) \ r(t)\ u(t-1) \end{bmatrix} \end{align}$$</p>
<p>The QP matrices must be constructed online, contrarily to the LTI case.</p>
<p>An LPV model can obtained by linearizing nonlinear model</p>
<p>​    $\begin{cases} \dot{x}_x(t)=f(x_c(t),u_c(t),p_c(t))\ y_c(t)=g(x_c(t),p_c(t)) \end{cases}$</p>
<p>​    where $p_c$ = a vector of exogeneous signals</p>
<p>Linearize:</p>
<p>​    $$\dot{x}<em>c(t) \simeq \underbrace{ \frac{\partial f}{\partial x}|</em>{\bar{x}_c,\bar{u}_c,\bar{p}<em>c}}</em>{A_c} (x_c(t)-\bar{x}<em>c) + \underbrace{ \frac{\partial f}{\partial u}|</em>{\bar{x}_c,\bar{u}_c,\bar{p}<em>c}}</em>{B_c} (u_c(t)-\bar{u}<em>c)+ \underbrace{ \left[ \frac{\partial f}{\partial p}|</em>{\bar{x}_c,\bar{u}_c,\bar{p}_c} f(\bar{x}_c,\bar{u}<em>c,\bar{p}<em>c) \right]}</em>{B</em>{vc}} \begin{bmatrix}[p_c(t)-\bar{p}_c\ 1]\end{bmatrix} $$</p>
<ul>
<li>convert $\begin{bmatrix} A_c, [B_c \ \ B_{vc}] \end{bmatrix}$ to discrete-time and get prediction model $(A, []B\ \ B_{vc})$</li>
<li>same thing for the output equation, to get matrices $C$ and $D_v$</li>
</ul>
<h1 id="LTV"><a href="#LTV" class="headerlink" title="LTV"></a>LTV</h1><p>Linear time-varying (LTV) model</p>
<ul>
<li><p>$\begin{align} x_{k+1}&amp;=A_k(t) x_k +B_k(t)u_k\ y_k&amp;=C_k(t)x_k \end{align}$</p>
</li>
<li><p>at each time the model can also change over the prediction horizon $k$</p>
</li>
<li><p>the optimization problem is still a QP</p>
<p>​    $$\begin{align} \min\limits_{z}\quad \frac{1}{2} z’H(t)z+\begin{bmatrix} x(t)\ r(t)\ u(t-1) \end{bmatrix}’ F(t)’ z’ \ \text{s.t.} \quad G(t)z \leq W(t)+S(t)\begin{bmatrix} x(t) \ r(t)\ u(t-1) \end{bmatrix} \end{align}$$</p>
</li>
<li><p> As for LPV-MPC, the QP matrices must be constructed online.</p>
</li>
</ul>
<ul>
<li>LTV/LPV model can be obtained by linearing nonlinear models</li>
<li>nominal trajectories:<ul>
<li>$U={\bar{u}_c(t),\bar{u}_c(t+T_s),\cdots,\bar{u}_c (t+(N-1)T_s)}$<ul>
<li>$U$=shifted previous optimal sequence, or reference trajectories.</li>
</ul>
</li>
<li>$P={\bar{p}_c(t),\bar{p}_c(t+T_s),\cdots,\bar{p}_c (t+(N-1)T_s)}$<ul>
<li>no preview: $\bar{p}_c(t+k)\equiv \bar{p}_c(t)$</li>
<li></li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhang-xiaoxue.github.io/2020/07/30/Model%20Predictive%20Control/Manage%20Papers/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/photo_blue.jpg">
      <meta itemprop="name" content="Xiaoxue Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiaoxue Zhang - NUS">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/07/30/Model%20Predictive%20Control/Manage%20Papers/" class="post-title-link" itemprop="url">Manage Papers about Prediction</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-07-30 12:00:00" itemprop="dateCreated datePublished" datetime="2020-07-30T12:00:00+08:00">2020-07-30</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2021-05-13 15:32:02" itemprop="dateModified" datetime="2021-05-13T15:32:02+08:00">2021-05-13</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Model-Predictive-Control/" itemprop="url" rel="index"><span itemprop="name">Model Predictive Control</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Manage-Papers"><a href="#Manage-Papers" class="headerlink" title="Manage Papers"></a>Manage Papers</h1><h1 id="Prediction"><a href="#Prediction" class="headerlink" title="Prediction"></a>Prediction</h1><p>Human motion prediction</p>
<h3 id="Survey-Paper"><a href="#Survey-Paper" class="headerlink" title="Survey Paper"></a>Survey Paper</h3><ul>
<li><input disabled="" type="checkbox"> Survey on Vision-Based Path Prediction. Springer, 2018.  <a href="Hirakawa2018_Chapter_SurveyOnVision-BasedPathPredic.pdf">Hirakawa2018_Chapter_SurveyOnVision-BasedPathPredic.pdf</a> </li>
</ul>
<h3 id="Social-Force"><a href="#Social-Force" class="headerlink" title="Social Force"></a>Social Force</h3><ul>
<li><input disabled="" type="checkbox"> Anticipative kinodynamic planning:multi-objective robot navigation in urban and dynamic environments  [Social Force.pdf](C:\Users\adminnus\OneDrive - National University of Singapore\B_Reading Materials\A_Path Planning\Papers\Prediction\Social Force.pdf) </li>
<li><input disabled="" type="checkbox"> Behavior estimation for a complete framework for human motion prediction in crowded environments [Social Force 2.pdf](C:\Users\adminnus\OneDrive - National University of Singapore\B_Reading Materials\A_Path Planning\Papers\Prediction\Social Force 2.pdf) </li>
</ul>
<h3 id="Probabilistic-Methods"><a href="#Probabilistic-Methods" class="headerlink" title="Probabilistic Methods"></a>Probabilistic Methods</h3><ul>
<li><p><input disabled="" type="checkbox">  Probabilistic Trajectory Prediction with Gaussian Mixture Models, Intelligent Vehicles Symposium, 2012. [Probabilistic Trajectory Prediction with Gaussian Mixture Models.pdf](C:\Users\adminnus\OneDrive - National University of Singapore\B_Reading Materials\A_Path Planning\Papers\Prediction\Probabilistic Trajectory Prediction with Gaussian Mixture Models.pdf).</p>
<blockquote>
<p>GMM: point estimate for model parameter</p>
<ul>
<li>Solving method: iterative EM</li>
<li>infer joint Gaussian mixture distribution $p(\mathbb x_f, \mathbb x_h)$, then predict by using conditional mixture density $p(\mathbb x_f | \mathbb x_h)$</li>
</ul>
<p>VGMM: prior distribution over parameters, then derive full Bayesian treatment.</p>
<ul>
<li>Not point estimate, parameters are given conjugate prior distribution. </li>
<li>Solving method: Variational Bayesian EMs</li>
<li>similarly, infer joint distribution, then obtian conditional distribution. </li>
</ul>
<p>Compare Two Methods.</p>
</blockquote>
</li>
<li><p><input disabled="" type="checkbox">  How Would Surround Vehicles Move? A Unified Framework for Maneuver Classification and Motion Prediction, IEEE Transactions on Intelligent Vehicles, 2018.  [How Would Surround Vehicles Move_A Unified Framework for Maneuver Classification and Motion Prediction.pdf](C:\Users\adminnus\OneDrive - National University of Singapore\B_Reading Materials\A_Path Planning\Papers\Prediction\How Would Surround Vehicles Move_A Unified Framework for Maneuver Classification and Motion Prediction.pdf) </p>
</li>
<li><p><input disabled="" type="checkbox">  Vehicle Speed Prediction Using a Markov Chain With Speed Constraints, IEEE Transactions on ITS. 2018. [Vehicle Speed Prediction Using a Markov Chain With Speed Constraints.pdf](C:\Users\adminnus\OneDrive - National University of Singapore\B_Reading Materials\A_Path Planning\Papers\Prediction\Vehicle Speed Prediction Using a Markov Chain With Speed Constraints.pdf)  </p>
</li>
</ul>
<h3 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h3><ul>
<li><input disabled="" type="checkbox"> Probabilistic Path Planning using Obstacle Trajectory Prediction [rrt* + LSTM], <a target="_blank" rel="noopener" href="http://cods-comad.in/2019/index.html">CoDS-COMAD ‘19</a> , 2019.  [Path Planning (rrt) + Obstacle Prediction_LSTM.pdf](Path Planning (rrt) + Obstacle Prediction_LSTM.pdf) </li>
<li><input disabled="" type="checkbox"> TraPHic: Trajectory Prediction in Dense and Heterogeneous Traffic Using Weighted Interactions [LSTM], CVPR, 2019.  <a href="Trajectory_Prediction_Heterogeneous_Traffic_LSTM_CVPR_2019_paper.pdf">Trajectory_Prediction_Heterogeneous_Traffic_LSTM_CVPR_2019_paper.pdf</a> </li>
<li><input disabled="" type="checkbox"> Robust Aleatoric Modeling for Future Vehicle Localization,  2019 CVPR <a target="_blank" rel="noopener" href="https://sites.google.com/view/ieeecvf-cvpr2019-precognition"><em>Precognition Workshop</em></a>, <a target="_blank" rel="noopener" href="http://openaccess.thecvf.com/content_CVPRW_2019/papers/Precognition/Hudnell_Robust_Aleatoric_Modeling_for_Future_Vehicle_Localization_CVPRW_2019_paper.pdf">Paper</a>.</li>
<li><input disabled="" type="checkbox"> </li>
</ul>
<h1 id="Learning-MPC"><a href="#Learning-MPC" class="headerlink" title="Learning MPC"></a>Learning MPC</h1><ul>
<li><input disabled="" type="checkbox"> Learning  [learning MPC_primal+dual.pdf](../B_Reading Materials/B_MPC+learning/learning MPC_primal+dual.pdf) </li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhang-xiaoxue.github.io/2020/07/30/Model%20Predictive%20Control/Probabilistic%20Trajectory%20Prediction%20with%20Gaussian%20Mixture%20Models/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/photo_blue.jpg">
      <meta itemprop="name" content="Xiaoxue Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiaoxue Zhang - NUS">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/07/30/Model%20Predictive%20Control/Probabilistic%20Trajectory%20Prediction%20with%20Gaussian%20Mixture%20Models/" class="post-title-link" itemprop="url">Probabilistic Trajectory Prediction with Gaussian Mixture Models</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-07-30 12:00:00" itemprop="dateCreated datePublished" datetime="2020-07-30T12:00:00+08:00">2020-07-30</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2021-05-13 15:32:02" itemprop="dateModified" datetime="2021-05-13T15:32:02+08:00">2021-05-13</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Model-Predictive-Control/" itemprop="url" rel="index"><span itemprop="name">Model Predictive Control</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Probabilistic-Trajectory-Prediction-with-Gaussian-Mixture-Models"><a href="#Probabilistic-Trajectory-Prediction-with-Gaussian-Mixture-Models" class="headerlink" title="Probabilistic Trajectory Prediction with Gaussian Mixture Models"></a>Probabilistic Trajectory Prediction with Gaussian Mixture Models</h1><h2 id="Trajectory-Representation"><a href="#Trajectory-Representation" class="headerlink" title="Trajectory Representation"></a>Trajectory Representation</h2><p>input data: short trajectory pieces.</p>
<p>Trajectory $T$:<br>$$<br>T = ((x_0,y_0,z_0),t0), \cdots, ((x_{N-1},y_{N-1},z_{N-1}),t_{N-1}) described by $p_X, p_y, p_z$<br>$$<br>described by $p_X, p_y, p_z$ or described by roll, pitch and yaw angle $\phi(t_i), \theta(t_i), \psi(t_i)$ and velocity $v_x, v_y,v_z$.</p>
<p>Chebyshev decomposition on the components of trajectory $\rightarrow$ coefficients as input features of GMM</p>
<ul>
<li><p>polynomial $T_n$ of degree $n$<br>$$<br>T_n (x) = \cos(n \arccos (x))<br>$$<br>in detail,<br>$$<br>T_0(x) = 1 \<br>T_1(x) = x \<br>T_{n+1}(x) = 2x T_n(x) - T_{n-1}(x), \ n\ge 1<br>$$</p>
</li>
<li><p>To approximate any arbitrary function $f(x)$ in $[-1,1]$, the Chebyshev coefficients are<br>$$<br>c_n = \frac {2}{N} \sum\limits_{k=0}^{N-1} f(x_k) T_n(x_k)<br>$$<br>where $x_k$ are N zeros of $T_N(x)$.</p>
<p>reformulate as<br>$$<br>f(x) \approx \sum\limits_{n=0}^{m-1} c_n T_n(x) -\frac{1}{2}c_0<br>$$</p>
</li>
</ul>
<h3 id="code"><a href="#code" class="headerlink" title="code"></a>code</h3><p><code>numpy.polynomial.chebyshev</code></p>
<table>
<thead>
<tr>
<th>Basics</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td><a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.polynomial.chebyshev.chebval.html#numpy.polynomial.chebyshev.chebval"><code>chebval</code></a>(x, c[, tensor])</td>
<td>Evaluate a Chebyshev series at points x.</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.polynomial.chebyshev.chebval2d.html#numpy.polynomial.chebyshev.chebval2d"><code>chebval2d</code></a>(x, y, c)</td>
<td>Evaluate a 2-D Chebyshev series at points (x, y).</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.polynomial.chebyshev.chebval3d.html#numpy.polynomial.chebyshev.chebval3d"><code>chebval3d</code></a>(x, y, z, c)</td>
<td>Evaluate a 3-D Chebyshev series at points (x, y, z).</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.polynomial.chebyshev.chebgrid2d.html#numpy.polynomial.chebyshev.chebgrid2d"><code>chebgrid2d</code></a>(x, y, c)</td>
<td>Evaluate a 2-D Chebyshev series on the Cartesian product of x and y.</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.polynomial.chebyshev.chebgrid3d.html#numpy.polynomial.chebyshev.chebgrid3d"><code>chebgrid3d</code></a>(x, y, z, c)</td>
<td>Evaluate a 3-D Chebyshev series on the Cartesian product of x, y, and z.</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.polynomial.chebyshev.chebroots.html#numpy.polynomial.chebyshev.chebroots"><code>chebroots</code></a>(c)</td>
<td>Compute the roots of a Chebyshev series.</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.polynomial.chebyshev.chebfromroots.html#numpy.polynomial.chebyshev.chebfromroots"><code>chebfromroots</code></a>(roots)</td>
<td>Generate a Chebyshev series with given roots</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>Fitting</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td><a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.polynomial.chebyshev.chebfit.html#numpy.polynomial.chebyshev.chebfit"><code>chebfit</code></a>(x, y, deg[, rcond, full, w])</td>
<td>Least squares fit of Chebyshev series to data.</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.polynomial.chebyshev.chebvander.html#numpy.polynomial.chebyshev.chebvander"><code>chebvander</code></a>(x, deg)</td>
<td>Pseudo-Vandermonde matrix of given degree.</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.polynomial.chebyshev.chebvander2d.html#numpy.polynomial.chebyshev.chebvander2d"><code>chebvander2d</code></a>(x, y, deg)</td>
<td>Pseudo-Vandermonde matrix of given degrees.</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.polynomial.chebyshev.chebvander3d.html#numpy.polynomial.chebyshev.chebvander3d"><code>chebvander3d</code></a>(x, y, z, deg)</td>
<td>Pseudo-Vandermonde matrix of given degrees.</td>
</tr>
</tbody></table>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhang-xiaoxue.github.io/2020/07/30/Model%20Predictive%20Control/Variational%20Inference/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/photo_blue.jpg">
      <meta itemprop="name" content="Xiaoxue Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiaoxue Zhang - NUS">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/07/30/Model%20Predictive%20Control/Variational%20Inference/" class="post-title-link" itemprop="url">Variational Inference</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-07-30 12:00:00" itemprop="dateCreated datePublished" datetime="2020-07-30T12:00:00+08:00">2020-07-30</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2021-05-13 15:32:02" itemprop="dateModified" datetime="2021-05-13T15:32:02+08:00">2021-05-13</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Model-Predictive-Control/" itemprop="url" rel="index"><span itemprop="name">Model Predictive Control</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Variational-Inference"><a href="#Variational-Inference" class="headerlink" title="Variational Inference"></a>Variational Inference</h1><p>The solution is obtained by exploring all possible input functions to find the one that maximizes, or minimizes, the functional. </p>
<ul>
<li><p>restriction : factorization assumption</p>
</li>
<li><p>log marginal probability<br>$$<br>\ln p(\mathbf X) = \mathcal L(q)+ KL(q||p)<br>$$</p>
<ul>
<li>This differs from our discussion of EM only in that the parameter vector $\theta$ no longer appears, because the parameters are now stochastic variables and are absorbed into $\mathbf Z$.</li>
<li>maximize the lower bound $\mathcal L$ = minimize the KL divergence.</li>
</ul>
</li>
</ul>
<p>In particular, there is no ‘over-fitting’ associated with highly flexible distributions. Using more flexible approximations simply allows us to approach the true posterior distribution more closely.</p>
<ul>
<li>One way to restrict the family of approximating distributions is to use a parametric distribution $q(Z|ω)$ governed by a set of parameters $ω$. The lower bound $\mathcal L(q)$ then becomes a function of $ω$, and we can exploit standard nonlinear optimization techniques to determine the optimal values for the parameters. </li>
</ul>
<p>Method:</p>
<ol>
<li><p>Factorized distribution approximate to true posterior distribution  –&gt;&gt; Mean field theory<br>$$<br>KL(p||q) \quad \iff \quad KL(q||p)<br>$$</p>
<ol>
<li><p>if we consider approximating a multimodal distribution by a unimodal one,</p>
<p>Both types of multimodality were encountered in Gaussian mixtures, where they manifested themselves as<br>multiple maxima in the likelihood function, and a variational treatment based on the minimization of $KL(q||p)$ will tend to find one of these modes.</p>
</li>
<li><p>if we were to minimize $KL(p||q)$, the resulting approximations would average across all of the modes and, in the context of the mixture model, would lead to poor predictive distributions (because the average of two good parameter values is typically itself not a good parameter value). It is possible to make use of $KL(p||q)$ to define a useful inference procedure, but this requires a rather different approach about expectation propagation.</p>
</li>
</ol>
<p>The two forms of KL divergence are members of the <em>alpha family</em> of divergence.</p>
</li>
</ol>
<h2 id="Variational-Mixture-of-Gaussian"><a href="#Variational-Mixture-of-Gaussian" class="headerlink" title="Variational Mixture of Gaussian"></a>Variational Mixture of Gaussian</h2><ul>
<li><p>Likelihood function $p(\mathbf Z| \mathbf \pi) = \prod\limits_{n=1}^N \prod\limits_{k=1}^K \pi_k^{z_{nk}}$</p>
</li>
<li><p>Conditional distribution of observed data $p(\mathbf X|\mathbf Z,\mu, \Lambda) = \prod\limits_{n=1}^N \prod\limits_{k=1}^K \mathcal N(\mathbf x_n|\mu_k,\Lambda_k^{-1})^{z_{nk}}$</p>
</li>
<li><p>Prior distribution: $p(\pi) = \mathrm{Dir}(\pi|\alpha_0)$,  $p(\mu,\Lambda) = p(\mu|\Lambda)p(\Lambda)=\prod\limits_{k=1}^N \mathcal N(\mu_k | m_0, (\beta_0\Lambda_k)^{-1}) \mathcal W(\Lambda_k|\mathbf W_0, \nu_0)$</p>
<p>Variables such as $\mathbb z_n$ that appear inside the plate are regarded as latent variables because the number of such variables grows with the size of the data set. By contrast, variables such as μ that are outside the plate are fixed in number independently of the size of the data set, and so are regarded as parameters</p>
</li>
</ul>
<h3 id="Variational-distrbution"><a href="#Variational-distrbution" class="headerlink" title="Variational distrbution"></a>Variational distrbution</h3><p>Joint distribution<br>$$<br>p(\mathbf{X}, \mathbf{Z}, \boldsymbol{\pi}, \boldsymbol{\mu}, \boldsymbol{\Lambda})=p(\mathbf{X} | \mathbf{Z}, \boldsymbol{\mu}, \boldsymbol{\Lambda}) p(\mathbf{Z} | \boldsymbol{\pi}) p(\boldsymbol{\pi}) p(\boldsymbol{\mu} | \boldsymbol{\Lambda}) p(\boldsymbol{\Lambda})<br>$$<br>Variational distribution (Assumption)<br>$$<br>q(\mathbf{Z}, \boldsymbol{\pi}, \boldsymbol{\mu}, \boldsymbol{\Lambda}) = q(\mathbf{Z})q(\boldsymbol{\pi}, \boldsymbol{\mu}, \boldsymbol{\Lambda})<br>$$<br>==Variational EM==</p>
<p>This effect can be understood qualitatively in terms of the automatic trade-off in a Bayesian model between fitting the data and the complexity of the model, in which the complexity penalty arises from components whose parameters are pushed away from their prior values. </p>
<p>Thus the optimization of the variational posterior distribution involves cycling between two stages analogous to the E and M steps of the maximum likelihood EM algorithm. </p>
<ul>
<li><p>Variational E-step</p>
<p>use the current distributions over the model parameters to evaluate the moments in (10.64), (10.65), and (10.66)<br>and hence evaluate $\mathbb E[z_{nk}] = r_{nk}$.</p>
</li>
<li><p>Variational M-step</p>
<p>keep these responsibilities fixed and use them to re-compute the variational distribution over the parameters using (10.57) and (10.59). In each case, we see that the variational posterior distribution has the same functional form as the corresponding factor in the joint distribution (10.41). This is a general result and is a consequence of the choice of conjugate distributions.</p>
</li>
</ul>
<p>==variational EM v.s. EM for maximum likelihood.==</p>
<ul>
<li>In fact if we consider the limit $N\rightarrow \infty$ then the Bayesian treatment converges to the maximum likelihood EM algorithm. </li>
<li>For anything other than very small data sets, the dominant computational cost of the variational algorithm for Gaussian mixturesa rises from the evaluation of the responsibilities, together with the evaluation and inversion of the weighted data covariance matrices. These computations mirror precisely those that arise in the maximum likelihood EM algorithm, and so there is little computational overhead in using this Bayesian approach as compared to the traditional maximum likelihood one. </li>
<li>The singularities that arise in maximum likelihood when a Gaussian component ‘collapses’ onto a specific data point are absent in the Bayesian treatment. Indeed, these singularities are removed if we simply introduce a prior and then use a MAP estimate instead of maximum likelihood. </li>
<li>Furthermore, there is no over-fitting if we choose a large number $K$ of components in the mixture. </li>
<li>Finally, the variational treatment opens up the possibility of determining the optimal number of components in the mixture without resorting to techniques such as cross validation.</li>
</ul>
<h3 id="Variational-lower-bound"><a href="#Variational-lower-bound" class="headerlink" title="Variational lower bound"></a>Variational lower bound</h3><p>Function:</p>
<ul>
<li>to monitor the bound during the re-estimation in order to test for convergence</li>
<li>provide a valuable check on both the mathematical expressions for the solutions and their software implementation, because at each step of the iterative re-estimation procedure the value of this bound should not decrease.</li>
<li>provide a deeper test of the correctness of both the mathematical derivation of the update equations and of their software implementation by using finite differences to check that each update does indeed give a (constrained) maximum of the bound</li>
</ul>
<p>lower bound provides an alternative approach for deriving the variational re-estimation equations in variational EM. To do<br>this we use the fact that, since the model has conjugate priors, the functional form of the factors in the variational posterior distribution is known, namely discrete for $\mathbf Z$, Dirichlet for $π$, and Gaussian-Wishart for $(μ_k,Λ_k)$. By taking general parametric forms for these distributions we can derive the form of the lower bound as a function of the parameters of the distributions. Maximizing the bound with respect to these  parameters then gives the required re-estimation equations.</p>
<h3 id="Predictive-density"><a href="#Predictive-density" class="headerlink" title="Predictive density"></a>Predictive density</h3><p>predictive density for a new value $\hat x$ of the observed variable.  corresponding to latent variable $\hat{\mathbf z}$.<br>$$<br>p(\widehat{\mathbf{x}} | \mathbf{X})=\sum_{\widehat{\mathbf{z}}} \iiint p(\widehat{\mathbf{x}} | \widehat{\mathbf{z}}, \mu, \Lambda) p(\widehat{\mathbf{z}} | \boldsymbol{\pi}) p(\boldsymbol{\pi}, \boldsymbol{\mu}, \boldsymbol{\Lambda} | \mathbf{X}) \mathrm{d} \boldsymbol{\pi} \mathrm{d} \boldsymbol{\mu} \mathrm{d} \boldsymbol{\Lambda} \<br>= \sum_{k=1}^K  \iiint \pi_k \mathcal N(\hat{\mathbf x} |\mu_k,\Lambda_k) q(\pi) q(\mu_k, \Lambda_k) d\pi d\mu_k d \Lambda_k<br>$$<br>remaining integrations can now be evaluated analytically giving a mixture of Student’s t-distributions:<br>$$<br>\begin{aligned}<br>p(\widehat{\mathbf{x}} | \mathbf{X})&amp;= \frac{1}{\widehat{\alpha}} \sum_{k=1}^{K} \alpha_{k} \operatorname{St}\left(\widehat{\mathbf{x}} | \mathbf{m}<em>{k}, \mathbf{L}</em>{k}, \nu_{k}+1-D\right) \<br>\qquad \mathbf{L}<em>{k}&amp;=\frac{\left(\nu</em>{k}+1-D\right) \beta_{k}}{\left(1+\beta_{k}\right)} \mathbf{W}_{k}<br>\end{aligned}<br>$$<br>where $\mathbf m_k$ is the mean of $k$th component.</p>
<h3 id="Determining-the-number-of-components"><a href="#Determining-the-number-of-components" class="headerlink" title="Determining the number of components."></a>Determining the number of components.</h3><p>variational lower bound can be used to determine a posterior distribution over the number $K$ of components in the mixture model.</p>
<p>If we have a mixture model comprising $K$ components, then each parameter setting will be a member of a family of $K!$ equivalent settings.</p>
<ul>
<li>in EM, this is irrelevant because the parameter optimization algorithm will, depending on the initialization<br>of the parameters, find one specific solution, and the other equivalent solutions play no role.</li>
<li>in Variational EM, we marginalize over all possible parameter values.</li>
<li>if the true posterior distribution is multimodal, variational inference based on the minimization of $KL(q||p)$ will tend to approximate the distribution in the neighborhood of one of the modes and ignore the others.</li>
<li>If we want to compare different value of $K$, we need to consider the multimodality.</li>
</ul>
<p>Solution: </p>
<ol>
<li>to add a term $\ln K!$ onto the lower bound when used for model comparison and averaging.</li>
<li>treat the mixing coefficients $π$ as parameters and make point estimates of their values by maximizing the lower bound with respect to $π$ instead of maintaining a probability distribution over them as in the fully Bayesian approach.<ul>
<li>This leads to the re-estimation equation and <u>this maximization is interleaved with the variational updates for the $q$ distribution over the remaining parameters</u>. </li>
<li>Components that provide insufficient contribution to explaining the data will have their mixing coefficients driven to zero during the optimization, and so they are effectively removed from the model through automatic relevance determination. This allows us to make a single training run in which we start with a relatively large initial value of K, and allow surplus components to be pruned out of the model. </li>
</ul>
</li>
</ol>
<p>==Comparison:==</p>
<ul>
<li>maximum likelihood would lead to values of the likelihood function that increase monotonically with K (assuming the singular solutions have been avoided, and discounting the effects of local maxima) and so cannot be used to determine an appropriate model complexity. </li>
<li>By contrast, Bayesian inference automatically makes the trade-off between model complexity and fitting the data.</li>
</ul>
<blockquote>
<p>maximum likelihood would lead to values of the likelihood function that increase monotonically with K (assuming the singular solutions have been avoided, and discounting the effects of local maxima) and so cannot be used to determine an appropriate model complexity. </p>
<p>By contrast, Bayesian inference automatically makes the trade-off between model complexity and fitting the data.</p>
</blockquote>
<h1 id="Simplified-description"><a href="#Simplified-description" class="headerlink" title="Simplified description"></a>Simplified description</h1><blockquote>
<p> Reference:  <a href="https://link.zhihu.com/?target=https://www.cnblogs.com/yifdu25/p/8181185.html">变分推断（Variational Inference）</a></p>
<p> <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/38740118">https://zhuanlan.zhihu.com/p/38740118</a> </p>
</blockquote>
<h2 id="Description"><a href="#Description" class="headerlink" title="Description"></a>Description</h2><p>based on input data to compute a distribution $P(x)$.</p>
<p>Idea: Use Gaussian distribution can function as <u>approximate distribution</u> to simulate the <u>real distribution</u> </p>
<p>&lt;用已知的分布模拟未知的分布&gt;</p>
<p>Parameters:</p>
<ul>
<li>input: $x$</li>
<li>hidden variable: $z$<ul>
<li>is parameter in real distribution. For GMM, $z$ is the mean and covariance of all gaussian distribution.</li>
</ul>
</li>
<li>Posterior distribution $P(z|x)$:<ul>
<li>using the data to guess the model. &lt;用输入去推断隐含变量&gt;</li>
</ul>
</li>
<li>likelihood distribution $P(x|z)$:<ul>
<li>distribution based on the model parameter.</li>
</ul>
</li>
<li>distribution of input $P(x)$</li>
<li>Prior distribution $q(z,v)$:<ul>
<li>the distribution to simulate the real distribution. $z$ is hidden variables, $v$ is the parameter of distribution about $z$, i.e., hyperparameter.</li>
<li>normally, the distribution about $z$ is conjugate distribution.  </li>
</ul>
</li>
</ul>
<p>Task:</p>
<p>adjust $v$ to make the approximate distribution close to the posterior distribution $p(z|x)$</p>
<img src="https://raw.githubusercontent.com/Lisnol1/PicGo--/master/v2-ef06fbce0bb4818363ed2010fc357fdf_r.jpg" style="zoom: 60%">

<p>Hope the posterior distribution and the prior distribution closed to 0. But the posterior distribution is unknown. Therefore, introduce the KL divergence and ELBO.<br>$$<br>\log p(x) = KL(q(z;v) || p(z|x)) + ELBO(v)<br>$$<br>because $\log p(x)$ is constant, the minimum KL divergence is the maximum ELBO.</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhang-xiaoxue.github.io/2020/07/30/Reinforcement%20Learning/CNN_Keras_vs_Torch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/photo_blue.jpg">
      <meta itemprop="name" content="Xiaoxue Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiaoxue Zhang - NUS">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/07/30/Reinforcement%20Learning/CNN_Keras_vs_Torch/" class="post-title-link" itemprop="url">CNN Keras vs Torch</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-07-30 12:00:00" itemprop="dateCreated datePublished" datetime="2020-07-30T12:00:00+08:00">2020-07-30</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2021-08-16 15:37:49" itemprop="dateModified" datetime="2021-08-16T15:37:49+08:00">2021-08-16</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Reinforcement-Learning/" itemprop="url" rel="index"><span itemprop="name">Reinforcement Learning</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="1-How-to-understand-parameters-in-CNN-layers"><a href="#1-How-to-understand-parameters-in-CNN-layers" class="headerlink" title="1. How to understand parameters in CNN layers"></a>1. How to understand parameters in CNN layers</h2><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gs7cf9eocej31eu0u01kx.jpg">

<p>There is an example to test how you really know this.</p>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gs7cghh4lnj31hc0nutea.jpg"></p>
<h2 id="2-How-to-calculate-parameter-numbers-in-CNN-layers"><a href="#2-How-to-calculate-parameter-numbers-in-CNN-layers" class="headerlink" title="2. How to calculate parameter numbers in CNN layers"></a>2. How to calculate parameter numbers in CNN layers</h2><p><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gs7ciyb301j31i70u07wh.jpg"></p>
<h2 id="3-Implement-difference-between-Keras-and-Torch"><a href="#3-Implement-difference-between-Keras-and-Torch" class="headerlink" title="3. Implement difference between Keras and Torch"></a>3. Implement difference between Keras and Torch</h2><p>In keras, we will start with <code>model = Sequential()</code> and add all the layers to model.</p>
<p>In pytorch, we will start by defining class and initialize it with all layers and then add forward function to define flow of data.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NeuralNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self , x</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<ol>
<li><p>Add convolution layer:</p>
<ol>
<li><p>Keras:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Conv2D(filters, kernel_size, strides, padding, activation=<span class="literal">None</span>, use_bias=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># &quot;padding=&#x27;valid&#x27;&quot; means there is no padding, &quot;padding=&#x27;same&#x27;&quot; means output dim is the same as input dim.</span></span><br></pre></td></tr></table></figure>

<p>if no padding and stride:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(Conv2D(<span class="number">32</span>, (<span class="number">5</span>, <span class="number">5</span>), input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"><span class="comment"># input dim: (28,28,1); filter num: 32; kernel dim: (5,5); activation: relu.</span></span><br><span class="line"><span class="comment"># output dim: (24,24,32)</span></span><br></pre></td></tr></table></figure>

<p>if has padding and stride:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.add(Conv2D(<span class="number">256</span>, kernel_size=<span class="number">3</span>, strides=<span class="number">1</span>,padding=‘same’, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"><span class="comment"># input dim: (24,24,32); filter num:256; kernel dim:(3,3), strid:(1,1), padding=(1,1); output dim: (24,24,32)</span></span><br></pre></td></tr></table></figure></li>
<li><p>Torch:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, padding_mode)</span><br></pre></td></tr></table></figure>

<p>if no padding and stride:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NeuralNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(NeuralNet, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>,<span class="number">32</span>,kernel_size=(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">        self.relu1 = nn.Relu()</span><br></pre></td></tr></table></figure>

<p>if has padding and stride:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">self.conv2 = nn.Conv2d(<span class="number">32</span>,<span class="number">256</span>,kernel_size=(<span class="number">3</span>,<span class="number">3</span>),stride=(<span class="number">1</span>,<span class="number">1</span>),padding=(<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">self.relu1 = nn.Relu()</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Here, <code>nn.relu()</code> has an argument <code>inplace</code>, which means the operation will be in-place. In other words,      <code>inplace=True</code> means that it will modify the input directly, without allocating any additional output. It can sometimes slightly decrease the memory usage, but may not always be a valid operation (because the original input is destroyed)。利用in-place计算可以节省内（显）存，同时还可以省去反复申请和释放内存的时间。但是会对原变量覆盖，只要不带来错误就用。</p>
</blockquote>
</li>
</ol>
</li>
<li></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhang-xiaoxue.github.io/2020/07/30/Model%20Predictive%20Control/Hybrid%20Toolbox/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/photo_blue.jpg">
      <meta itemprop="name" content="Xiaoxue Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiaoxue Zhang - NUS">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/07/30/Model%20Predictive%20Control/Hybrid%20Toolbox/" class="post-title-link" itemprop="url">Hybrid Toolbox</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-07-30 12:00:00" itemprop="dateCreated datePublished" datetime="2020-07-30T12:00:00+08:00">2020-07-30</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2021-08-16 15:18:57" itemprop="dateModified" datetime="2021-08-16T15:18:57+08:00">2021-08-16</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Model-Predictive-Control/" itemprop="url" rel="index"><span itemprop="name">Model Predictive Control</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="linear-system"><a href="#linear-system" class="headerlink" title="linear system"></a>linear system</h2><p>###<code>lincon</code> </p>
<p><code>lincon</code>  Constrained linear quadratic controller for linear systems</p>
<ul>
<li><p><strong><code>L=lincon(SYS,TYPE,COST,INTERVAL,LIMITS,QPSOLVER)</code></strong>  build a regulator (or a controller for reference tracking) based on a finite time linear quadratic constrained optimal control formulation</p>
<ul>
<li><p><strong>SYS</strong> is the discrete-time linear time-invariant model <code>(A,B,C,D,TS)</code></p>
</li>
<li><p><strong>TYPE:</strong> 2 types, <code>&#39;reg&#39; </code>  = regulator;  <code>&#39;track&#39;</code> = controller for reference tracking    </p>
<ol>
<li><p>Regulator:</p>
<p>$\min x’(N)Px(N) + \sum\limits_{k=0}^{N-1} x’(k)Qx(k) + u’(k)Ru(k) + \rho*\epsilon ^2$</p>
<p>  s.t.      $ y_{min} - \epsilon &lt;= y(k) &lt;=y_{max} + \epsilon, k=1,…,N_{cy}$<br>​             $u_{min} &lt;= u(k) &lt;=u_{max},       k=0,…,N_{cu}$<br>​             $u(k) = Kx(k),            k&gt;=N_u$</p>
</li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x(t+<span class="number">1</span>) = A x(t) + B u(t)</span><br><span class="line">  y(t) = C x(t) + D u(t)</span><br></pre></td></tr></table></figure>
<ol start="2">
<li><p>Reference Tracking :</p>
<p>$\min \sum\limits_{k=0}^{N-1} [y(k)-r]’S[y(k)-r] + \Delta u’(k) T \Delta u(k) + \rho*\epsilon^2$</p>
<p>  s.t.     $y_{min} - \epsilon &lt;= y(k)  &lt;=y_{max} + \epsilon,\  k=1,…,N_{cy}$<br>​            $u_{min} &lt;= u(k)  &lt;=u_{max}, \      k=0,…,N_{cu}$<br>​            $\Delta u_{min} &lt;= du(k) &lt;=\Delta u_{max}, \     k=0,…,N_{cu}$<br>​             $\Delta u(k) = 0,       \   k&gt;=N_u$</p>
</li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x(t+<span class="number">1</span>) = Ax(t) + B [u(t<span class="number">-1</span>)+du(t)]   <span class="comment">%du(t) = u(t)-u(t-1) = input increment</span></span><br><span class="line">  y(t) = Cx(t) + D [u(t<span class="number">-1</span>)+du(t)]</span><br></pre></td></tr></table></figure></li>
<li><p><strong>COST</strong> is a structure of weights with fields:</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">.Q = weight Q on states             [ x&#x27;(k)Qx(k) ]           (regulator only)</span><br><span class="line">.R = weight R on inputs             [ u&#x27;(k)Ru(k) ]           (regulator only)</span><br><span class="line">.P = weight P on final state        [ x&#x27;(N)Px(N) ]           (regulator only)</span><br><span class="line">.S = weight S on outputs            [ (y(k)-r)&#x27;S(y(k)-r) ]   (tracking only)</span><br><span class="line">.T = weight T on input increments   [ du&#x27;(k) T du(k) ]       (tracking only)</span><br><span class="line">.rho = weight on slack var          [ rho*<span class="built_in">eps</span>^<span class="number">2</span>  ]           (regulator and tracking)  <span class="comment">%rho=Inf means hard output constraints</span></span><br><span class="line">.K = feedback gain (default: K=<span class="number">0</span>)   [ u(k)=K*x(k) <span class="keyword">for</span> k&gt;=Nu] (only regulator)</span><br></pre></td></tr></table></figure>

<blockquote>
<p><em>Only for regulators:</em><br>   <em>If <code>COST.P=&#39;lqr&#39;</code> then P is chosen as the solution of the LQR problem with weights Q,R, and K is chosen as the corresponding LQR gain.</em><br>   <em>If <code>COST.P=&#39;lyap&#39;</code> then P is chosen as the solution of the Lyapunov equation <code>A&#39;PA - P + Q = 0</code>, and K=0 (default).</em></p>
</blockquote>
</li>
<li><p><strong>INTERVAL</strong> is a structure of number of input and output optimal control steps </p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">.N   = optimal control interval over which the cost <span class="function"><span class="keyword">function</span> <span class="title">is</span> <span class="title">summed</span></span></span><br><span class="line">.Nu  = number of free optimal control moves u(<span class="number">0</span>),...,u(Nu<span class="number">-1</span>)</span><br><span class="line">.Ncy = output constraints are checked up to time k=Ncy</span><br><span class="line">.Ncu = input constraints are checked up to time k=Ncu</span><br></pre></td></tr></table></figure></li>
<li><p><strong>LIMITS</strong> is a structure of constraints with fields:</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">.umin = lower bounds on inputs             [ u(k)&gt;=umin ]</span><br><span class="line">.umax = upper bounds on inputs             [ u(k)&lt;=umax ]</span><br><span class="line">.ymin = lower bounds on outputs            [ y(k)&gt;=ymin ]</span><br><span class="line">.ymax = upper bounds on outputs            [ y(k)&lt;=ymax ]</span><br><span class="line">.dumin = lower bounds on input increments  [ du(k)&gt;=dumin ] (only tracking)</span><br><span class="line">.dumax = upper bounds on input increments  [ du(k)&lt;=dumax ] (only tracking)</span><br></pre></td></tr></table></figure>

<blockquote>
<p> <em>O</em>nly for regulators:*<br>   <em>If <code>COST.P=&#39;lqr&#39;</code> then P is chosen as the solution of the LQR problem with weights Q,R, and K is chosen as the corresponding LQR gain.</em><br>   <em>If <code>COST.P=&#39;lyap&#39;</code> then P is chosen as the solution of the Lyapunov equation <code>A&#39;PA - P + Q = 0</code>, and K=0 (default).</em>    </p>
</blockquote>
</li>
<li><p><strong>QPSOLVER</strong>  specifies the QP used for evaluating the control law. Valid options are:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#39;qpact&#39;      active set method</span><br><span class="line">&#39;quadprog&#39;   QUADPROG from Optimization Toolbox</span><br><span class="line">&#39;qp&#39;         QP from Optimization Toolbox</span><br><span class="line">&#39;nag&#39;        QP from NAG Foundation Toolbox</span><br><span class="line">&#39;cplex&#39;      QP from Ilog Cplex</span><br></pre></td></tr></table></figure></li>
<li><p><strong>YZEROCON</strong> enforce <em>output constraints</em> also at prediction time k=0 if YZEROCON=1 (default: YZEROCON=0). </p>
<blockquote>
<p><em>If YEZEROCON is a 0/1 vector of the same dimension as the output vector, then only those outputs where YZEROCON(i)=1 are constrained at time k=0.</em></p>
</blockquote>
</li>
</ul>
<p><strong>Time-varying formulation</strong>: Use the same syntax as above, with input arguments as follow: </p>
</li>
</ul>
<ul>
<li><p><code>SYS</code> = cell array of linear models, <code>SYS&#123;i&#125;</code>=model used to predict at step t+i-1</p>
</li>
<li><p><code>COST</code> = cell array of structures of weights: <code>COST&#123;i&#125;.Q</code>, <code>COST&#123;i&#125;.R</code>, etc.  Only <code>COST&#123;1&#125;.rho</code> is used for penalty soft constraint penalty, <code>COST&#123;i&#125;.rho</code> is ignored for i&gt;1.</p>
</li>
<li><p><code>LIMITS</code> = cell arrays of structures of upper and lower bounds: <code>LIMITS&#123;i&#125;.umin</code>, etc. The constraints <code>LIMITS&#123;i&#125;</code> refer to time index t+i, for both inputs and outputs.<code>linsfun</code></p>
</li>
</ul>
<h3 id="sim-for-lincon"><a href="#sim-for-lincon" class="headerlink" title="sim for lincon"></a><code>sim</code> for <code>lincon</code></h3><p><code>sim</code> : Closed-loop simulation of constrained optimal controllers for linear systems.</p>
<p> <code>[X,U,T,Y]=sim(LINCON,MODEL,refs,x0,Tstop,u0,qpsolver,verbose)</code> simulates the closed-loop of the linear system <strong>MODE</strong>L with the controller <strong>LINCON</strong> based on quadratic programming.</p>
<p>Usually, <strong>LINCON</strong> is based on model <strong>MODEL</strong> (nominal closed-loop).</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Input: </span><br><span class="line"></span><br><span class="line">LINCON      = optimal controller</span><br><span class="line">refs        = structure or references with fields; ref.y  output references  (only <span class="keyword">for</span> tracking)</span><br><span class="line">x0          = initial state</span><br><span class="line">Tstop       = total simulation time  (total number of steps = Tstop/LINCON.Ts)</span><br><span class="line">u0          = input at time t=<span class="number">-1</span>     (only <span class="keyword">for</span> tracking)</span><br><span class="line">qpsolver    = QP solver (<span class="built_in">type</span> HELP QPSOL <span class="keyword">for</span> details)</span><br><span class="line">verbose     = verbosity level (<span class="number">0</span>,<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p> <code> refs.y</code> has as many columns as the number of outputs</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Output <span class="keyword">arguments</span>:</span><br><span class="line">  X is the sequence of states, with as many columns as the number of states.</span><br><span class="line">  U is the sequence of inputs, with as many columns as the number of inputs.</span><br><span class="line">  T is the vector of time steps.</span><br><span class="line">  I is the sequence of region numbers</span><br><span class="line">  Y is the sequence of outputs, with as many columns as the number of outputs.</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Without output arguments, sim produces a plot of the trajectories</p>
</blockquote>
<blockquote>
<p> <strong>LINCON</strong> objects based on time-varying prediction models/weights/limits can be simulated in closed-loop with LTI models. Time-varying simulation models are not supported, use custom for-loops instead.</p>
</blockquote>
<h3 id="sim-general"><a href="#sim-general" class="headerlink" title="sim (general)"></a><code>sim </code>(general)</h3><p><code>sim</code> : Simulate a Simulink model</p>
<p><code>SimOut = sim(&#39;MODEL&#39;, PARAMETERS)</code> simulates your Simulink model,  </p>
<p><code>&#39;PARAMETERS&#39;</code> represents a list of parameter name-value pairs, a structure  containing parameter settings, or a configuration set. </p>
<p> <code>SimOut</code> returned by the sim command is an object that contains all of the logged simulation results.</p>
<p> <code>PARAMETERS</code> can be used to override existing block diagram configuration parameters for the duration of the simulation.</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">This syntax is referred to as the <span class="string">&#x27;Single-Output Format&#x27;</span>.</span><br><span class="line">paramNameValStruct.SimulationMode = <span class="string">&#x27;rapid&#x27;</span>;</span><br><span class="line">paramNameValStruct.AbsTol         = <span class="string">&#x27;1e-5&#x27;</span>;</span><br><span class="line">paramNameValStruct.SaveState      = <span class="string">&#x27;on&#x27;</span>;</span><br><span class="line">paramNameValStruct.StateSaveName  = <span class="string">&#x27;xoutNew&#x27;</span>;</span><br><span class="line">paramNameValStruct.SaveOutput     = <span class="string">&#x27;on&#x27;</span>;</span><br><span class="line">paramNameValStruct.OutputSaveName = <span class="string">&#x27;youtNew&#x27;</span>;</span><br><span class="line">simOut = sim(<span class="string">&#x27;vdp&#x27;</span>,paramNameValStruct)</span><br></pre></td></tr></table></figure>



<h3 id="kalman"><a href="#kalman" class="headerlink" title="kalman"></a><code>kalman</code></h3><p><code>KALMAN</code>Design Kalman filter for constrained optimal controllers</p>
<p> <strong><code>KALMAN(CON,Q,R)</code></strong> design a state observer for the linear model <strong><code>(A,B,C,D)=CON.model</code></strong> which controller <code>CON</code> is based on,  using Kalman filtering techniques. The resulting observer is stored in the <code>&#39;Observer&#39;</code> field of the controller object. The controller object can be either of class <code>LINCON</code> or <code>EXPCON</code>.</p>
<p> <strong><code>Q</code></strong> is the <span style="border-bottom:2px dashed red;">covariance matrix of state noise</span>, <strong><code>R</code></strong> is the <span style="border-bottom:2px dashed red;">covariance matrix of outputnoise</span>.</p>
<p> <strong><code>Kest=KALMAN(CON,Q,R)</code></strong> also return the state observer as an LTI object.</p>
<p> <strong><code>Kest</code></strong> receives <code>u[n]</code> and <code>y[n]</code> as inputs (in this order), and provides the best estimated state <code>x[n|n-1]</code> of <code>x[n]</code> given the past measurements <code>y[n-1]</code>, <code>y[n-2]</code>,<code>...</code></p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x[n+<span class="number">1</span>|n] = Ax[n|n<span class="number">-1</span>] + Bu[n] + L(y[n] - Cx[n|n<span class="number">-1</span>] - Du[n])</span><br></pre></td></tr></table></figure>

<p> <strong><code>Kest=KALMAN(CON,Q,R,ymeasured)</code></strong> assumes that only the outputs specified in vector <code>ymeasured</code> are measurable outputs. In this case, <code>R</code> is a <code>nym-by-nym</code> matrix, where <code>nym</code> is the number of measured outputs.</p>
<p> <strong><code>[Kest,M]=KALMAN(CON,Q,R,ymeasured)</code></strong> also returns the gain <code>M</code> which allows computing the measurement update</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x[n|n]  = x[n|n<span class="number">-1</span>] + M(y[n] - Cx[n|n<span class="number">-1</span>] - Du[n])</span><br></pre></td></tr></table></figure>

<p>  For time-varying prediction models, the first model <code>CON.model&#123;1&#125;</code> is used to build the Kalman filter, as it is the model of the process for the current time step.</p>
<h3 id="expcon"><a href="#expcon" class="headerlink" title="expcon"></a><code>expcon</code></h3><p><code>EXPCON</code> Explicit controllers (for linear/hybrid systems)</p>
<p> **<code>E=EXPCON(C,RANGE,OPTIONS)</code> **convert controller C to piecewise affine explicit form.</p>
<p> <strong><code>C</code></strong> is a constrained optimal controller for linear systems or hybrid systems (an object of class @LINCON or @HYBCON)</p>
<p><strong><code>RANGE</code></strong> defines the range of the parameters the explicit solution is found with respect to (it may be different from the limits over variables imposed in the control law). <code>RANGE</code> is a structure with fields:</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">.xmin, xmax = range of states            [ xmin &lt;= x &lt;= xmax ]       (linear and hybrid)</span><br><span class="line">.umin, umax = range of inputs            [ umin &lt;= u &lt;= umax ]       (linear w/ tracking)</span><br><span class="line">.refymin, refymax = range of output refs [ refymin &lt;= r.y &lt;= refymax]  (linear w/ tracking and hybrid)</span><br><span class="line">.refxmin, refxmax = range of state refs  [ refxmin &lt;= r.x &lt;= refxmax ]  (hybrid)</span><br><span class="line">.refumin, refumax = range of input refs  [ refumin &lt;= r.u &lt;= refumax ]  (hybrid)</span><br></pre></td></tr></table></figure>

<p>  For hybrid controllers, <code>refxmin</code>,<code>refxmax</code>,<code>refumin</code>,<code>refumax</code>,<code>refymin</code>,<code>refymax</code> must have dimensions consistent with the number of indices specified in <code>C.ref</code> (type “help hybcon” for details)</p>
<p> <strong><code>OPTIONS</code></strong> defines various options for computing the explicit control law:</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">.lpsolver    = LP solver (<span class="built_in">type</span> HELP LPSOL <span class="keyword">for</span> details)</span><br><span class="line">.qpsolver    = QP solver (<span class="built_in">type</span> HELP QPSOL <span class="keyword">for</span> details)</span><br><span class="line">.fixref      = structure with fields <span class="string">&#x27;y&#x27;</span>,<span class="string">&#x27;x&#x27;</span>,<span class="string">&#x27;u&#x27;</span> defining references that are fixed at 				   given values, therefore simplifying the parametric solution [hybrid only]</span><br><span class="line">.valueref    = structure with fields <span class="string">&#x27;y&#x27;</span>,<span class="string">&#x27;x&#x27;</span>,<span class="string">&#x27;u&#x27;</span> of values at which references are fixed  				 [hybrid only]</span><br><span class="line">.flattol       Tolerance <span class="keyword">for</span> a polyhedral set to be considered flat</span><br><span class="line">.waitbar       display waitbar (only <span class="keyword">for</span> hybrid)</span><br><span class="line">.verbose     = level of verbosity &#123;<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>&#125; of mp-PWA solver</span><br><span class="line">.mplpverbose = level of verbosity &#123;<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>&#125; of mp-LP solver</span><br><span class="line">.uniteeps    = tolerance <span class="keyword">for</span> judging convexity of the union of polyhedra</span><br><span class="line">.join        = flag <span class="keyword">for</span> reducing the complexity by joining regions whose union is a convex 				set.</span><br><span class="line">.reltol      = tolerance used <span class="keyword">for</span> several polyhedral operations</span><br><span class="line">.sequence    = flag <span class="keyword">for</span> keeping the entire optimal control sequence as an explicit 						<span class="function"><span class="keyword">function</span> <span class="title">of</span> <span class="title">the</span> <span class="title">parameters</span> <span class="title">also</span> <span class="title">in</span> <span class="title">the</span> <span class="title">linear</span> <span class="title">case</span>. <span class="title">Flag</span> <span class="title">ignored</span> <span class="title">in</span> <span class="title">the</span> 				<span class="title">hybrid</span> <span class="title">case</span>: <span class="title">sequence</span> <span class="title">always</span> <span class="title">stored</span> <span class="title">with</span> <span class="title">quadratic</span> <span class="title">costs</span>, <span class="title">never</span> <span class="title">stored</span> 					<span class="title">with</span> <span class="title">inf</span>-<span class="title">norms</span>.     </span></span><br></pre></td></tr></table></figure>

<p>  <strong>Example:</strong> to fix the reference signal for <code>x(1)</code>,<code>x(2)</code> at the values <code>rx(1)=0.6</code>,<code> rx(2)=-1.4</code> and mantain the reference <code>rx(3)</code> for <code>x(3)</code> as a free parameter, specify <code>options.fixref.x=[1 2]</code>, <code>options.valueref.x=[0.6 -1.4]</code>.</p>
<blockquote>
<p>Note: @MPC objects from MPC Toolbox are no longer supported, as they are handled directly in the MPC Toolbox since R2014b.</p>
</blockquote>
<blockquote>
<p>See also <code>EXPCON/EVAL</code> for the order states and references are stored inside the parameter vector.</p>
</blockquote>
<p>##Modelling </p>
<h3 id="tf"><a href="#tf" class="headerlink" title="tf"></a><code>tf</code></h3><ol>
<li>Create transfer function model;      2.  convert to transfer function model</li>
</ol>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sys = tf(Numerator,Denominator) </span><br><span class="line">sys = tf(Numerator,Denominator,Ts) </span><br><span class="line">sys = tf(M) </span><br><span class="line">sys = tf(Numerator,Denominator,ltisys) </span><br><span class="line">tfsys = tf(sys) </span><br><span class="line">tfsys = tf(sys, <span class="string">&#x27;measured&#x27;</span>)</span><br><span class="line">tfsys = tf(sys, <span class="string">&#x27;noise&#x27;</span>)</span><br><span class="line">tfsys = tf(sys, <span class="string">&#x27;augmented&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>Example1:</strong></p>
<p>Create Transfer Function with One Input and Two Outputs:</p>
<p>​    Create the following transfer function model:</p>
<p>​    $$H(p)=\begin{bmatrix} \frac{p+1}{p^2+2*p+2} \   \frac{1}{p}\end{bmatrix}$$</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Numerator = &#123;[<span class="number">1</span> <span class="number">1</span>] ; <span class="number">1</span>&#125;;</span><br><span class="line">Denominator = &#123;[<span class="number">1</span> <span class="number">2</span> <span class="number">2</span>] ; [<span class="number">1</span> <span class="number">0</span>]&#125;;</span><br><span class="line">H = tf(Numerator,Denominator,<span class="string">&#x27;InputName&#x27;</span>,<span class="string">&#x27;current&#x27;</span>,...</span><br><span class="line">        <span class="string">&#x27;OutputName&#x27;</span>,&#123;<span class="string">&#x27;torque&#x27;</span> <span class="string">&#x27;ang. velocity&#x27;</span>&#125;,...</span><br><span class="line">        <span class="string">&#x27;Variable&#x27;</span>,<span class="string">&#x27;p&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>Example2</strong></p>
<p>Convert State-Space Model to Transfer Function:</p>
<p>​    Compute the transfer function of the following state-space model:</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sys = ss([<span class="number">-2</span> <span class="number">-1</span>;<span class="number">1</span> <span class="number">-2</span>],[<span class="number">1</span> <span class="number">1</span>;<span class="number">2</span> <span class="number">-1</span>],[<span class="number">1</span> <span class="number">0</span>],[<span class="number">0</span> <span class="number">1</span>]);</span><br><span class="line">tf(sys)</span><br></pre></td></tr></table></figure>

<h3 id="ss"><a href="#ss" class="headerlink" title="ss"></a><code>ss</code></h3><p>Create state-space model, convert to state-space model</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sys = ss(A,B,C,D) </span><br><span class="line">sys = ss(A,B,C,D,Ts) </span><br><span class="line">sys = ss(D)</span><br><span class="line">sys = ss(A,B,C,D,ltisys) </span><br><span class="line">sys_ss = ss(sys) </span><br><span class="line">sys_ss = ss(sys,<span class="string">&#x27;minimal&#x27;</span>)</span><br><span class="line">sys_ss = ss(sys,<span class="string">&#x27;explicit&#x27;</span>)</span><br><span class="line">sys_ss = ss(sys, <span class="string">&#x27;measured&#x27;</span>)</span><br><span class="line">sys_ss = ss(sys, <span class="string">&#x27;noise&#x27;</span>)</span><br><span class="line">sys_ss = ss(sys, <span class="string">&#x27;augmented&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><code>sys = ss(A,B,C,D) </code>creates a state-space model object representing the continuous-time state-space model</p>
<p>​    $x=Ax+Bu$</p>
<p>​    $y=Cx+Du$</p>
<p>​        For a model with <code>Nx</code> states, <code>Ny</code> outputs, and <code>Nu</code> inputs:</p>
<p>​        - <code>A</code> is an <code>Nx</code>-by-<code>Nx</code> real- or complex-valued matrix.</p>
<p>​        - <code>B</code> is an <code>Nx</code>-by-<code>Nu</code> real- or complex-valued matrix.</p>
<ul>
<li><p><code>C</code> is an <code>Ny</code>-by-<code>Nx</code> real- or complex-valued matrix.</p>
</li>
<li><p><code>D</code> is an <code>Ny</code>-by-<code>Nu</code> real- or complex-valued matrix.</p>
<blockquote>
<p>To set <code>D = 0</code> , set <code>D</code> to the scalar <code>0</code> (zero), regardless of the dimension.</p>
</blockquote>
</li>
</ul>
<p><code>sys = ss(A,B,C,D,Ts) </code>creates the discrete-time model</p>
<p>​    $x[n+1]=Ax[n]+Bu[n]$</p>
<p>​    $y[n]=Cx[n]+Du[n]$</p>
<p>with sample time <code>Ts</code> (in seconds). Set <code>Ts = -1</code> or <code>Ts = []</code> to leave the sample time unspecified.</p>
<h3 id="ssdata"><a href="#ssdata" class="headerlink" title="ssdata"></a><code>ssdata</code></h3><p><code>ssdata</code> :   Quick access to state-space data.</p>
<p><code>[A,B,C,D] = ssdata(SYS)</code> returns the A,B,C,D matrices of the state-space model <code>SYS</code>.  If <code>SYS</code> is not a state-space model, it is first converted to the state-space representation. If <code>SYS</code> is in descriptor form (nonempty<br>E matrix), an equivalent explicit form is first derived. If <code>SYS</code> has internal delays, A,B,C,D are obtained by first setting all internal delays to zero (delay-free dynamics).</p>
<p><code>[A,B,C,D,TS] = ssdata(SYS)</code> also returns the sample time <code>TS</code>. Other properties of <code>SYS</code> can be accessed using struct-like dot syntax (for example, <code>SYS.StateName</code>).</p>
<p>Support for arrays of state-space models:</p>
<p><code>[A,B,C,D,TS] = ssdata(SYS,J1,...,JN)</code> extracts the data for the (J1,…,JN) entry in the model array SYS.</p>
<p>If all models in <code>SYS</code> have the same order, <code>ssdata</code> returns multi-dimensional arrays A,B,C,D where A(:,:,k), B(:,:,k), C(:,:,k), D(:,:,k) are the state-space matrices of the k-th model SYS(:,:,k).</p>
<p>If the models in SYS have variable order, use the syntax <code>[A,B,C,D] = ssdata(SYS,&#39;cell&#39;)</code> to extract the state-space matrices of each model as separate cells in the cell arrays A,B,C,D.</p>
<h3 id="c2d"><a href="#c2d" class="headerlink" title="c2d"></a><code>c2d</code></h3><p>Convert model from continuous to discrete time</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sysd = c2d(sys,Ts)</span><br><span class="line">sysd = c2d(sys,Ts,method)</span><br><span class="line">sysd = c2d(sys,Ts,opts)</span><br><span class="line">[sysd,G] = c2d(sys,Ts,method)</span><br><span class="line">[sysd,G] = c2d(sys,Ts,opts)</span><br></pre></td></tr></table></figure>



<h3 id="step"><a href="#step" class="headerlink" title="step"></a><code>step</code></h3><p>Step response plot of dynamic system; step response data</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">step(sys) </span><br><span class="line">step(sys,Tfinal)</span><br><span class="line">step(sys,t)</span><br><span class="line">step(sys1,sys2,...,sysN)</span><br><span class="line">step(sys1,sys2,...,sysN,Tfinal)</span><br><span class="line">step(sys1,sys2,...,sysN,t)</span><br><span class="line">y = step(sys,t)</span><br><span class="line">[y,t] = step(sys)</span><br><span class="line">[y,t] = step(sys,Tfinal)</span><br><span class="line">[y,t,x] = step(sys) </span><br><span class="line">[y,t,x,ysd] = step(sys) </span><br><span class="line">[y,...] = step(sys,...,options)</span><br></pre></td></tr></table></figure>



<h2 id="solution"><a href="#solution" class="headerlink" title="solution"></a>solution</h2><h3 id="dare"><a href="#dare" class="headerlink" title="dare"></a><code>dare</code></h3><p><code>dare</code> :  Solve <u>discrete-time algebraic Riccati equations</u>.</p>
<p><code>[X,L,G] = dare(A,B,Q,R,S,E)</code> computes the unique stabilizing solution <code>X</code>  of the discrete-time algebraic Riccati equation $E’XE = A’XA - (A’XB + S)(B’XB + R)^{-1}  (A’XB + S)’ + Q$ or, equivalently (if R is nonsingular) $E’XE = F’XF - F’XB(B’XB + R)^{-1}  B’XF + Q - SR^{-1} S’$  with  $F:=A-BR^{-1}S’$.</p>
<p>When omitted, $R$, $S$ and $E$ are set to the default values $R=I$ , $S=0$ , and $E=I$.  Beside the solution X, dare also returns the gain matrix $G = (B’XB + R)^{-1}(B’XA + S’)$, and the vector $L$ of closed-loop eigenvalues (i.e., EIG(A-B*G,E)).</p>
<p><code>[X,L,G,REPORT] = dare(...)</code> returns a diagnosis <code>REPORT</code> with value:</p>
<ul>
<li>-1 if the Symplectic matrix has eigenvalues on the unit circle</li>
<li>-2 if there is no finite stabilizing solution X</li>
<li>Frobenius norm of relative residual if X exists and is finite. This syntax does not issue any error message when X fails to exist.</li>
</ul>
<p><code>[X1,X2,D,L] = dare(A,B,Q,...,&#39;factor&#39;)</code> returns two matrices <code>X1</code>, <code> X2</code> and a diagonal scaling matrix <code>D</code> such that $X = D(X_2/X_1)D$. The vector $L$ contains the closed-loop eigenvalues.  All outputs are empty when the associated Symplectic matrix has eigenvalues on the unit circle</p>
<h3 id="dlqr"><a href="#dlqr" class="headerlink" title="dlqr"></a><code>dlqr</code></h3><p><code>dlqr</code> :  Linear-quadratic regulator design for discrete-time systems.</p>
<p><code>[K,S,E] = dlqr(A,B,Q,R,N)</code>  calculates the optimal gain matrix $K$ such that the state-feedback law  <code>u[n] = -Kx[n]</code>  minimizes the cost function</p>
<pre><code>  J = Sum &#123;x&#39;Qx + u&#39;Ru + 2*x&#39;Nu&#125;
</code></pre>
<p>subject to the state dynamics  <code>x[n+1] = Ax[n] + Bu[n]</code>.  </p>
<p>The matrix <code>N</code> is set to zero when omitted.  Also returned are the <u>Riccati equation solution <code>S</code></u> and <u>the closed-loop eigenvalues <code>E</code></u> : </p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A&#x27;SA - S - (A&#x27;SB+N) (R+B&#x27;SB)^(<span class="number">-1</span>) (B&#x27;SA+N&#x27;) + Q = <span class="number">0</span>,   E = EIG(A-B*K)</span><br></pre></td></tr></table></figure>


<h3 id="lqr"><a href="#lqr" class="headerlink" title="lqr"></a><code>lqr</code></h3><p><code>lqr</code> : Linear-quadratic regulator design for state space systems.</p>
<p><code>[K,S,E] = lqr(SYS,Q,R,N)</code> calculates the optimal gain matrix <code>K</code> such that:</p>
<ul>
<li><p>For a continuous-time state-space model SYS, the state-feedback law <code>u = -Kx</code>  minimizes the cost function</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">J = Integral &#123;x&#x27;Qx + u&#x27;Ru + <span class="number">2</span>*x&#x27;Nu&#125; dt</span><br></pre></td></tr></table></figure>

<p>subject to the system dynamics  <code>dx/dt = Ax + Bu</code></p>
</li>
<li><p>For a discrete-time state-space model <code>SYS</code>, <code>u[n] = -Kx[n]</code> minimizes</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">J = Sum &#123;x&#x27;Qx + u&#x27;Ru + <span class="number">2</span>*x&#x27;Nu&#125;</span><br></pre></td></tr></table></figure>

<p>subject to  <code>x[n+1] = Ax[n] + Bu[n]</code>.</p>
</li>
</ul>
<p>The matrix <code>N</code> is set to zero when omitted.  Also returned are the solution <u><code>S</code> of the associated algebraic Riccati equation</u> and the <u>closed-loop eigenvalues <code>E = EIG(A-B*K)</code></u> .</p>
<p><code>[K,S,E] = lqr(A,B,Q,R,N)</code> is an equivalent syntax for continuous-time models with dynamics <code> dx/dt = Ax + Bu</code></p>
<h3 id="operspec"><a href="#operspec" class="headerlink" title="operspec"></a><code>operspec</code></h3><p><code>operspec</code> :  Create operating point specifications for Simulink model.</p>
<p><code>OP = operspec(&#39;sys&#39;)</code> returns an operating point specification object <code>OP</code>, for a Simulink model <code>&#39;sys&#39;</code>. Edit the default operating point specifications directly or use get and set. Use the operating point specifications object with the function <code>FINDOP</code> to  <span style="border-bottom:2px dashed red;">find operating points</span>  based on the specifications. Use these operating points with the function <code>LINEARIZE</code> to create linearized models.</p>
<p><code>OP = operspec(&#39;sys&#39;, N)</code> returns an N-dimensional column vector of the default operating point specification objects for a Simulink model <code>&#39;sys&#39;</code>.</p>
<p><code>OP = operspec(&#39;sys&#39;, SIZE)</code> returns an array of the default operating point specification objects. The size of OP is specified in the SIZE vector. For example, <code>operspec(&#39;vdp&#39;, [2,3])</code> returns a 2-by-3 matrix of default operating point specifications for the Simulink model <code>&#39;vdp&#39;</code>.</p>
<h3 id="findop"><a href="#findop" class="headerlink" title="findop"></a><code>findop</code></h3><p> <code>findop</code> : Find operating points from specifications or simulation</p>
<h3 id="place"><a href="#place" class="headerlink" title="place"></a><code>place</code></h3><p><code>place</code>  Pole placement design</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">K = place(A,B,p)</span><br><span class="line">[K,prec,message] = place(A,B,p)</span><br></pre></td></tr></table></figure>

<p>Given the single- or multi-input system $x=Ax+Bu$, and a vector <code>p</code> of desired self-conjugate closed-loop pole locations, <code>place</code> computes a gain matrix <code>K</code> such that the state feedback <code>u=-Kx</code> places the closed-loop poles at the locations <code>p</code>. In other words, the eigenvalues of <em>A</em> – <em>BK</em> match the entries of <code>p</code> (up to the ordering).</p>
<p><code>K = place(A,B,p)</code> places the desired closed-loop poles <code>p</code> by computing a state-feedback gain matrix <code>K</code>. All the inputs of the plant are assumed to be control inputs. The length of <code>p</code> must match the row size of <code>A</code>. <code>place</code> works for multi-input systems and is based on the algorithm from [<a target="_blank" rel="noopener" href="https://localhost:31515/static/help/control/ref/place.html#bq1no8b-1">1]</a>. This algorithm uses the extra degrees of freedom to find a solution that minimizes the sensitivity of the closed-loop poles to perturbations in <em>A</em> or <em>B</em>.</p>
<p><code>[K,prec,message] = place(A,B,p)</code> returns <code>prec</code>, an estimate of how closely the eigenvalues of <em>A</em> – <em>BK</em> match the specified locations <code>p</code> (<code>prec</code> measures the number of accurate decimal digits in the actual closed-loop poles). If some nonzero closed-loop pole is more than 10% off from the desired location, <code>message</code> contains a warning message.</p>
<h3 id="mpc"><a href="#mpc" class="headerlink" title="mpc"></a><code>mpc</code></h3><p><code>mpc</code>  Create an mpc controller.</p>
<p><code>MPCOBJ = mpc(PLANT)</code> creates the mpc object based on the linear plant model PLANT, which must be a SS, TF, ZPK or a linear model from System Identification Toolbox such as IDSS, IDTF, IDPROC, IDPOLY and IDGREY.</p>
<p><code>MPCOBJ = mpc(PLANT,TS)</code> specifies a sampling time for the mpc controller. A continuous-time PLANT model is discretized with sampling time <code>TS</code>.  A <span style="border-bottom:1px dashed blue;">discrete-time</span>   <code>PLANT model</code> is <em>resampled</em> to sampling time TS.</p>
<p><code>MPCOBJ = mpc(PLANT,TS,P)</code> specifies the prediction horizon <code>P</code>. <code>P</code> is a positive, finite <em>integer</em>.</p>
<p><code>MPCOBJ = mpc(PLANT,TS,P,M)</code> specifies the control horizon <code>M</code>. <code>M</code> is either an integer (&lt;= P) or a vector of blocked moves such that <code>sum(M)&lt;= P</code>.</p>
<p><code>MPCOBJ = mpc(PLANT,TS,P,M,Weights,MV,OV,DV)</code> also allows you to specify Weights, constraints on MV, MV rates and plant outputs, scale factors, as well as other properties with structures Weights, MV, OV and DV in that order. Those properties can also be specified using either</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET(MPCOBJ,Property1,Value1,Property2,Value2,...)</span><br></pre></td></tr></table></figure>
<p>or</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MPCOBJ.Property = Value</span><br></pre></td></tr></table></figure>

<p>Disturbance models and operating conditions can be specified using the syntax:</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">MPCOBJ = mpc(MODELS,TS,P,M) where MODELS is a structure containing </span><br><span class="line">MODELS.Plant         = plant model (LTI or linear model from System Identification 							   Toolbox).</span><br><span class="line">      .Disturbance   = model describing the input disturbances. This model is assumed to 						be driven by unit variance white noise. </span><br><span class="line">      .Noise         = model describing the plant output measurement noise. This model is 						 assumed to be driven by unit variance white noise.</span><br><span class="line">      .Nominal       = structure specifying the plant nominal conditions at which the 						   plant was linearized.</span><br><span class="line"> </span><br><span class="line">    MPCOBJ = mpc creates an empty mpc object</span><br></pre></td></tr></table></figure>



<h3 id="initial"><a href="#initial" class="headerlink" title="initial"></a><code>initial</code></h3><p><code>initial</code>  Initial condition response of state-space models.</p>
<p><code>initial(SYS,X0)</code> plots the undriven response of the state-space model SYS (created with SS) with initial condition X0 on the states. This response is characterized by the equations<br>                     .<br>  Continuous time:  $ x = A x ,\  y = C x ,\  x(0) = x_0 $</p>
<p>  Discrete time:  $x(k+1) = Ax(k), \  y(k) = Cx(k), \ x(0) = x_0 $</p>
<p>The time range and number of points are chosen automatically.</p>
<p><code>initial(SYS,X0,T)</code> uses the time vector <code>T</code> for simulation (expressed in the time units of SYS). For discrete-time models, T should be of the form Ti:Ts:Tf where Ts is the sample time. For continuous-time models, T should be of the form Ti:dt:Tf where dt is the sampling period for the discrete approximation of SYS. </p>
<p><code>initial(SYS,X0,T)</code> uses the time vector T for simulation (expressed in the time units of SYS). For discrete-time models, T should be of the form Ti:Ts:Tf where Ts is the sample time. For continuous-time models, T should be of the form Ti:dt:Tf where dt is the sampling period for the discrete approximation of SYS. </p>
<h2 id="run-sim"><a href="#run-sim" class="headerlink" title="run sim"></a>run sim</h2><h3 id="lsim"><a href="#lsim" class="headerlink" title="lsim"></a><code>lsim</code></h3><p><code>lsim</code>  Simulate time response of dynamic systems to arbitrary inputs.</p>
<p><code>lsim(SYS,U,T)</code> plots the time response of the dynamic system SYS to the input signal described by U and T. The time vector T is expressed in the  time units of SYS and consists of regularly spaced time samples. The matrix U has as many columns as inputs in SYS and its i-th row specifies the input value at time T(i). For example, <code>t = 0:0.01:5;   u = sin(t);   lsim(sys,u,t)</code>  simulates the response of a single-input model SYS to the input <code>u(t)=sin(t)</code> during 5 time units.</p>
<p>For discrete-time models, U should be sampled at the same rate as SYS (T is then redundant and can be omitted or set to the empty matrix). For continuous-time models, choose the sampling period T(2)-T(1) small enough to accurately describe the input U.  lsim issues a warning when U is undersampled and hidden oscillations may occur.</p>
<h3 id="msgbox"><a href="#msgbox" class="headerlink" title="msgbox"></a><code>msgbox</code></h3><p><code>msgbox</code>  : Create message dialog box</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">f = msgbox(message)</span><br><span class="line">f = msgbox(message,title)</span><br><span class="line">f = msgbox(message,title,icon)</span><br><span class="line">f = msgbox(message,title,<span class="string">&#x27;custom&#x27;</span>,icondata,iconcmap)</span><br><span class="line">f = msgbox(___,createmode)</span><br></pre></td></tr></table></figure>

<h3 id="warndlg"><a href="#warndlg" class="headerlink" title="warndlg"></a><code>warndlg</code></h3><p>Create warning dialog box</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">f = warndlg(msg)</span><br><span class="line">f = warndlg(msg,title)</span><br><span class="line">f = warndlg(msg,title,opts)</span><br><span class="line">f = warndlg</span><br></pre></td></tr></table></figure>

<h3 id="waitfor"><a href="#waitfor" class="headerlink" title="waitfor"></a><code>waitfor</code></h3><p><code>waitfor</code> : Block execution and wait for condition [after operation, will terminate the message box] </p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">waitfor(mo)</span><br><span class="line">waitfor(mo,propname)</span><br><span class="line">waitfor(mo,propname,propvalue)</span><br></pre></td></tr></table></figure>

<p>Examples:</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mydlg = warndlg(<span class="string">&#x27;This is a warning.&#x27;</span>, <span class="string">&#x27;A Warning Dialog&#x27;</span>);</span><br><span class="line">waitfor(mydlg);</span><br><span class="line"><span class="built_in">disp</span>(<span class="string">&#x27;This prints after you close the warning dialog.&#x27;</span>);</span><br></pre></td></tr></table></figure>



<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gcf：get current <span class="built_in">figure</span>；<span class="comment">%当前figure</span></span><br><span class="line">gca：get current axes；<span class="comment">%当前坐标轴</span></span><br><span class="line">gcbo：get callback object <span class="comment">%调用callback的对象句柄</span></span><br></pre></td></tr></table></figure>




      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhang-xiaoxue.github.io/2020/06/30/Chance%20Constraints/Chance-Constrained%20Optimal%20Path%20Planning%20with%20Obstacles/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/photo_blue.jpg">
      <meta itemprop="name" content="Xiaoxue Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiaoxue Zhang - NUS">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/06/30/Chance%20Constraints/Chance-Constrained%20Optimal%20Path%20Planning%20with%20Obstacles/" class="post-title-link" itemprop="url">Chance-Constrained Optimal Path Planning with Obstacles</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-06-30 12:00:00" itemprop="dateCreated datePublished" datetime="2020-06-30T12:00:00+08:00">2020-06-30</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2021-08-16 15:06:48" itemprop="dateModified" datetime="2021-08-16T15:06:48+08:00">2021-08-16</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Chance-Constraints/" itemprop="url" rel="index"><span itemprop="name">Chance Constraints</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Chance-Constrained-Optimal-Path-Planning-with-Obstacles"><a href="#Chance-Constrained-Optimal-Path-Planning-with-Obstacles" class="headerlink" title="Chance-Constrained Optimal Path Planning with Obstacles"></a>Chance-Constrained Optimal Path Planning with Obstacles</h1><p>Prior works: Set-Bound Uncertainty </p>
<p>Key idea: use bounds on the probability of collision to approximate the nonconvex chance-constrained optimization problem as a disjunctive convex problem. Then, solve by Branch-and-Bound techniques.</p>
<p>Target: linearm discrete-time system. </p>
<p>UAV. Uncertainty:</p>
<ol>
<li><p>location is not exactly known, but is estimated using a system model, interior sensors, and/or global position system. distribution may be generated with estimation technique, like KF. </p>
<p>$\rightarrow$ initial position is Gaussian distribution.</p>
</li>
<li><p>system model are approximations of true system model and these dynamixss are not fully known.</p>
<p>$\rightarrow$ model uncertainty to be Gaussian white noise </p>
</li>
<li><p>disturbances makes the turue trajecotyr. deviate from the palnned trajectory.</p>
<p>$\rightarrow$ modeled as Gaussian noise on dynamics.</p>
</li>
</ol>
<p>Prior Method: Set-bounded uncertainty models. to make sure the disturbance do not exceed the bounds.</p>
<p>Chance Constraints:</p>
<ul>
<li>Advantages over set-bounded approach:<ul>
<li>disturbances are represented using a stochastic model, rather than set-bounded one. </li>
<li>When use KF as localization, state estimate is a probabilsitic function with mean and covariancel</li>
</ul>
</li>
</ul>
<p>Existing CCP of linear system s.t. Gaussian uncertainty in convex region.</p>
<p>This paper extend to nonconvex region.</p>
<ul>
<li>Key: bound the probability of collision, give conservative approximation, formulate as disjunctive convex program, solve by Branch-and-Bound techniques.</li>
</ul>
<p>Convex region:</p>
<p>Nonconvex region:</p>
<ul>
<li>Early, convert problem into set-bound by ensuring 3-$\sigma$ confidence region. Then, can solve. But fail to ding a feasible solution. </li>
<li>Particle-based approach. Approximate the chance constraint, but not guarantee satisfaction of constraint. Can use arbitrary uncertainty distribution, rather than only Gaussian. But Computational intensive.</li>
<li>Anylytic bound to ensure the satifaction of constraints. little conservatism.</li>
</ul>
<h3 id="System-model"><a href="#System-model" class="headerlink" title="System model:"></a>System model:</h3><p>$$<br>\mathbf{x}<em>{t+1}=A \mathbf{x}</em>{t}+B \mathbf{u}<em>{t}+\omega</em>{t}<br>$$</p>
<p>$\omega_t$ is Gaussian white noise with $\omega_t \sim \mathcal{N}(0,Q)$</p>
<ul>
<li><p>polygonal convex stay-in regions $\mathcal{I}$: states much remain<br>$$<br>\mathcal{I} \Longleftrightarrow \bigwedge_{t \in T(\mathcal{I})} \bigwedge_{i \in G(\mathcal{I})} \mathbf{a}<em>{i}^{\prime} \mathbf{x}</em>{t} \leq b_{i}<br>$$</p>
</li>
<li><p>Polygonal convex obstacles: outside of which state must remain.<br>$$<br>\mathcal{O} \Longleftrightarrow \bigwedge_{t \in T(\mathcal{O})} \bigvee_{i \in G(\mathcal{O})} \mathbf{a}<em>{i}^{\prime} \mathbf{x}</em>{t} \geq b_{i}<br>$$<br><img src="https://raw.githubusercontent.com/Lisnol1/PicGo--/master/20190829192920.png" style="zoom:30%"> <img src="https://raw.githubusercontent.com/Lisnol1/PicGo--/master/20190829193046.png" style="zoom:33%"></p>
<blockquote>
<p>Note that nonconvex obstacles can be created by composing several convex obstacles.</p>
</blockquote>
</li>
</ul>
<h3 id="Problem-formulation"><a href="#Problem-formulation" class="headerlink" title="Problem formulation:"></a>Problem formulation:</h3><p>Problem 1: Chance-constrained path-planning problem:<br>$$<br>\begin{array}=<br>&amp;{\min\limits_{\mathbf{u}<em>{0}, \ldots, \mathbf{u}</em>{k-1}}  g\left(\mathbf{u}<em>{0}, \ldots, \mathbf{u}</em>{k-1}, \overline{\mathbf{x}}<em>{0}, \ldots, \overline{\mathbf{x}}</em>{k}\right)} \ {\text{subject to: }} \<br>&amp;{\overline{\mathbf{x}}<em>{k}=\mathbf{x}</em>{\mathrm{goal}}} \<br>&amp;{\mathbf{x}<em>{t+1}=A \mathbf{x}</em>{t}+B \mathbf{u}<em>{t}+\omega</em>{t}} \<br>&amp;{\mathbf{x}<em>{0} \sim \mathcal{N}\left(\hat{\mathbf{x}}</em>{0}, P_{0}\right) \omega_{t} \sim \mathcal{N}(0, Q)} \<br>&amp;{P \left( \left(\bigwedge_{i=1}^{N_{\mathcal{I}}} \mathcal{I}<em>{i}\right) \wedge \left(\bigwedge</em>{j=1}^{N_{O}} \mathcal{O}<em>{j}\right)  \right) \geq 1-\Delta}<br>\end{array}<br>$$<br>where $g(\cdot)$ is a piecewise linear cost function, $N</em>{\mathcal{I}}$ and $N_{\mathcal{O}}$ are number of stay-in regions and obstacles. $\overline{\mathbb{x}}$ means the expectation of $\mathbb{x}$. </p>
<p>Difficulty of solving:</p>
<ol>
<li>evaluating the chance constraint requires the <u>computation of the integral of a multivariable Gaussian distribution over a finite, nonconvex region</u>. This cannot be carried out in the closed form, and approximate techniques such as sampling are time consuming and introduce approximation error.</li>
<li>even if this integral could be computed efficiently, its value is <u>nonconvex in the decision variables</u> due to the disjunctions in $\mathcal{O}_i$ . $\longrightarrow$ the resulting optimization problem is intractable. A typical approach to dealing with nonconvex feasible spaces is the <u>branch-and-bound method</u>, which decomposes a nonconvex problem into a tree of convex problems. However, the branch-and-bound method cannot be directly applied, since the nonconvex chance constraint cannot be decomposed trivially into subproblems.</li>
</ol>
<h2 id="Preliminary"><a href="#Preliminary" class="headerlink" title="Preliminary:"></a>Preliminary:</h2><h3 id="Disjunctive-convex-programs"><a href="#Disjunctive-convex-programs" class="headerlink" title="Disjunctive convex programs:"></a>Disjunctive convex programs:</h3><p>$$<br>\begin{aligned}<br>&amp;{\min <em>{X} h(X)} \<br>{\text { subject to : }} \<br>&amp;{f</em>{\text {eq }}(X)=0} \<br>&amp;{\bigwedge_{i=1}^{n_{\text {dis }}} \bigvee_{j=1}^{n_{c l}} c_{i j}(X) \leq 0}<br>\end{aligned}<br>$$</p>
<p>where $c_{ij}(X)$ are convex function of $X$. $n_{\text{dis}}$ and $n_{\text{cl}}$ are the number of disjunctions and clauses within each disjunction.</p>
<h3 id="Disjunctive-linear-program"><a href="#Disjunctive-linear-program" class="headerlink" title="Disjunctive linear program:"></a>Disjunctive linear program:</h3><p>Same as above, but the $f_{\text{eq}}(X)$ and $c_{ij}(X)$ are linear function of $X$.</p>
<h3 id="Difficulty-of-disjunctive-convex-program"><a href="#Difficulty-of-disjunctive-convex-program" class="headerlink" title="Difficulty of disjunctive convex program:"></a>Difficulty of disjunctive convex program:</h3><p>disjunction render the feasible region nonconvex. Nonconvex programs  are intractable.</p>
<p><strong>Method:</strong> </p>
<ul>
<li>Decompose  the problem into a finite number of convex subproblems. The number of convex subproblems is exponential in the number of disjunctions $n_{\text{dis}}$. Brach-and-bound can find the global optimal solution while solving only small subset.</li>
</ul>
<h3 id="Propogation"><a href="#Propogation" class="headerlink" title="Propogation"></a>Propogation</h3><p>initial state: Gaussian $\mathcal{N}(\hat{\mathbb{x}}<em>0, P_0)$ +  dynamics : linear  +  noise: Gaussian $\longrightarrow$ future state is Gaussian<br>$$<br>\begin{aligned}<br>p(X_t|\mathbb{u}</em>{0,\cdots,k-1}) &amp;\sim \mathcal{N}(\mu_t,\Sigma_t)\<br>\mu_t &amp; =\sum\limits_{i=0}^{t-1}A^{t-i-1}B\mathbb{u}_i + A^t \hat{\mathbb{x}}<em>0 \quad {\text{linear equation}}\<br>\sum_t &amp;= \sum\limits</em>{t=0}^{t-1} A^iQ(A^T)^i + A^tP_0(A^T)^t \quad {\text{not about control inputs}}<br>\end{aligned}<br>$$</p>
<h3 id="Linear-Chance-Constraints-as-Deterministic-Linear-Constraints"><a href="#Linear-Chance-Constraints-as-Deterministic-Linear-Constraints" class="headerlink" title="Linear Chance Constraints as Deterministic Linear Constraints"></a>Linear Chance Constraints as Deterministic Linear Constraints</h3><p>Gaussian distribution:</p>
<ul>
<li><p>pdf: $f(x|\mu,\sigma^2)=\frac{1}{\sqrt{2\pi \sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$</p>
</li>
<li><p>cdf: $\Phi(x) = \frac{1}{\sqrt{2\pi}} \int\limits_{-\inf}^x e^{- \frac{t^2}{2}} dt$</p>
</li>
<li><p>erf: $\operatorname{erf}(x) = \frac{2}{\sqrt{\pi}} \int\limits_0^x e^{-t^2} dt$   (gives the probability of a random variable with normal distribution of mean 0 and variance 1/2 falling in the range $[-x,x]$)</p>
</li>
<li><p>Gaussian form translation: $f(x|\mu,\sigma^2)=\frac{1}{\sigma} \varphi(\frac{x-\mu}{\sigma})$</p>
</li>
<li></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhang-xiaoxue.github.io/2020/06/30/Chance%20Constraints/Chance-constrained%20Collision%20Avoidance%20for%20MAVs%20in%20Dynamics%20Environments/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/photo_blue.jpg">
      <meta itemprop="name" content="Xiaoxue Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiaoxue Zhang - NUS">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/06/30/Chance%20Constraints/Chance-constrained%20Collision%20Avoidance%20for%20MAVs%20in%20Dynamics%20Environments/" class="post-title-link" itemprop="url">Chance-constrained Collision Avoidance for MAVs in Dynamics Environments</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-06-30 12:00:00" itemprop="dateCreated datePublished" datetime="2020-06-30T12:00:00+08:00">2020-06-30</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2021-08-16 15:05:39" itemprop="dateModified" datetime="2021-08-16T15:05:39+08:00">2021-08-16</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Chance-Constraints/" itemprop="url" rel="index"><span itemprop="name">Chance Constraints</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Chance-constrained-Collision-Avoidance-for-MAVs-in-Dynamics-Environments"><a href="#Chance-constrained-Collision-Avoidance-for-MAVs-in-Dynamics-Environments" class="headerlink" title="Chance-constrained Collision Avoidance for MAVs in Dynamics Environments"></a>Chance-constrained Collision Avoidance for MAVs in Dynamics Environments</h1><p>Chance-constrained nonlinear model predictive control (CCNMPC)</p>
<ul>
<li>assume uncertainties as Gaussian distribution, transform chance constraints into deterministic constraints</li>
</ul>
<h2 id="Model"><a href="#Model" class="headerlink" title="Model:"></a>Model:</h2><ol>
<li><p>robot model:<br>$$<br>\mathbf{x}<em>{i}^{k+1}=\mathbf{f}</em>{i}\left(\mathbf{x}<em>{i}^{k}, \mathbf{u}</em>{i}^{k}\right)+\omega_{i}^{k}, \quad \mathbf{x}<em>{i}^{0} \sim \mathcal{N}\left(\hat{\mathbf{x}}</em>{i}^{0}, \Gamma_{i}^{0}\right),\quad \omega_i^k\sim\mathcal{N}(0,Q_i^k)<br>$$<br>where $\mathbf{x}<em>{i}^{k}=\left[\mathbf{p}</em>{i}^{k}, \mathbf{v}<em>{i}^{k}, \phi</em>{i}^{k}, \theta_{i}^{k}, \psi_{i}^{k}\right]^{T} \in \mathcal{X}<em>{i} \subset \mathbb{R}^{n</em>{x}}$, the mean and covariance of initial state$\mathbf{x}_i^0$ are obtained by state estimator (UKF). </p>
</li>
<li><p>Obstacle model:</p>
<p>$o\in \mathcal{I}_0={1,2,\cdots,n_0} \subset \mathbb{N}$ at position $\mathbf{p}_o \in \mathbb{R}^3$, can be represented by <em>ellipsoid</em> $S_0$ with semi-principal axes $(a_0,b_o,c_o)$ and rotation matrix $R_o$. </p>
<p>moving obstacles has constant velocity with Gaussian noise $\omega_o(t)\sim\mathcal{N}(0,Q_o(t))$ in acceleration, i.e. $\ddot{\mathbf{p}}_o=\omega_o(t)$. estimate and predict the future position and uncertainty by linear KF.</p>
</li>
<li><p>Collision Chance Constraints:</p>
<ol>
<li><p>Collision condition:</p>
<ul>
<li><p>collision of robot $i$ with robot $j$<br>$$<br>C_{i j}^{k} :=\left{\mathbf{x}<em>{i}^{k} |\left|\mathbf{p}</em>{i}^{k}-\mathbf{p}<em>{j}^{k}\right| \leq r</em>{i}+r_{j}\right}<br>$$</p>
</li>
<li><p>collision of robot $i$ with obstacle $o$:</p>
<p>obstacle: enlarged ellipsoid and check if the robot is inside it.<br>$$<br>C_{i o}^{k} :=\left{\mathbf{x}<em>{i}^{k} |\left|\mathbf{p}</em>{i}^{k}-\mathbf{p}<em>{o}^{k}\right|</em>{\Omega_{i o}} \leq 1\right},\quad<br>\Omega_{i o}=R_{o}^{T} \operatorname{diag}\left(1 /\left(a_{o}+r_{i}\right)^{2}, 1 /\left(b_{o}+r_{i}\right)^{2}, 1 /\left(c_{o}+r_{i}\right)^{2}\right) {R_{o}}<br>$$</p>
</li>
</ul>
</li>
<li><p>Chance constraints:<br>$$<br>\begin{array}{ll}{\operatorname{Pr}\left(\mathbf{x}<em>{i}^{k} \notin C</em>{i j}^{k}\right) \geq 1-\delta_{r},} &amp; {\forall j \in \mathcal{I}, j \neq i} \ {\operatorname{Pr}\left(\mathbf{x}<em>{i}^{k} \notin C</em>{i o}^{k}\right) \geq 1-\delta_{o},} &amp; {\forall o \in \mathcal{I}_{o}}\end{array}<br>$$</p>
</li>
</ol>
</li>
<li><p>Problem Formulation: </p>
<p>optimization problem with $N$ time steps and planning horizon $\tau=N\Delta t$, $\Delta t$ is time step.<br>$$<br>\begin{aligned} \min <em>{\hat{x}</em>{i}^{1}, \cdots, u_{i}^{0}, N-1} \quad &amp; \sum_{k=0}^{N-1} J_{i}^{k}\left(\hat{\mathbf{x}}<em>{i}^{k}, \mathbf{u}</em>{i}^{k}\right)+J_{i}^{N}\left(\hat{\mathbf{x}}<em>{i}^{N}\right) \ \text { s.t. }\quad &amp; \mathbf{x}</em>{i}^{0}=\hat{\mathbf{x}}<em>{i}(0), \quad \hat{\mathbf{x}}</em>{i}^{k}=\mathbf{f}<em>{i}\left(\hat{\mathbf{x}}</em>{i}^{k-1}, \mathbf{u}<em>{i}^{k-1}\right) \ &amp; \operatorname{Pr}\left(\mathbf{x}</em>{i}^{k} \notin C_{i j}^{k}\right) \geq 1-\delta_{r}, \forall j \in \mathcal{I}, j \neq i \ &amp; \operatorname{Pr}\left(\mathbf{x}<em>{i}^{k} \notin C</em>{i o}^{k}\right) \geq 1-\delta_{o}, \forall o \in \mathcal{I}<em>{o} \ &amp; \mathbf{u}</em>{i}^{k-1} \in \mathcal{U}<em>{i}, \quad \hat{\mathbf{x}}</em>{i}^{k} \in \mathcal{X}_{i} \ &amp; \forall k \in{1, \ldots, N} \end{aligned}<br>$$</p>
</li>
<li><p>Compute uncertainty propagation</p>
<p>Methods:</p>
<blockquote>
<p>Y. Z. Luo and Z. Yang, “A review of uncertainty propagation in orbital mechanics,” <em>Progr. Aerosp. Sci.</em>, vol. 89, pp. 23–39, 2017.</p>
</blockquote>
</li>
</ol>
<ul>
<li>Unscented transformation<blockquote>
<p>A.Vo ̈lzandK.Graichen,“Stochastic model predictive control of nonlinear continuous-time systems using the unscented transformation,” in<em>Proc. Eur. Control Conf.</em>, 2015, pp. 3365–3370.</p>
</blockquote>
<ul>
<li>polynomial chaos expansions</li>
</ul>
<blockquote>
<p>A. Mesbah, S. Streif, R. Findeisen, and R. D. Braatz, “Stochastic nonlinear model predictive control with probabilistic constraints,” in <em>Proc. Amer. Control Conf.</em>, 2014, pp. 2413–2419.</p>
</blockquote>
</li>
</ul>
<p>These methods are computational intensive and only outperform linearization methods when the propagation time is very long.</p>
<p>   In this paper, propagate the uncertainty using EKF-type update.<br>$$<br>\Gamma_{i}^{k+1}={F_{i}^{k}} {\Gamma_{i}^{k}} {F_{i}^{k}}^{T}+Q_{i}^{k}<br>$$<br>${\Gamma_{i}^{k}}$ is the state uncertainty covariance at time $k$, $F_{i}^{k}=\left.\frac{\partial \mathbf{f}<em>{i}}{\partial \mathbf{x}</em>{i}}\right|<em>{\hat{\mathbf{x}}</em>{i}^{k-1}, \mathbf{u}_{i}^{k}}$ is the state transition matrix of robot.</p>
<h2 id="Chance-Constraints"><a href="#Chance-Constraints" class="headerlink" title="Chance Constraints:"></a>Chance Constraints:</h2><p>Idea: linearize the collision conditions to get linear chance constraints. Then reformulate them into deterministic constraints</p>
<ol>
<li><p>Linear Constraints:<br>$$<br>\operatorname{Pr}(\mathbf{a}^T \mathbf{x}\leq b) \leq \delta<br>$$<br>$\mathbf{x}$ Follows Gaussian distribution, the chance constraint can be transformed into deterministic constraint</p>
<p><strong>Lemma 1:</strong></p>
<p>Given a multivariate random variable $\mathbf{x}\sim\mathcal{N}(\hat{\mathbf{x}},\Sigma)$, then<br>$$<br>\operatorname{Pr}\left(\mathbf{a}^{T} \mathbf{x} \leq b\right)=\frac{1}{2}+\frac{1}{2} \operatorname{erf}\left(\frac{b-\mathbf{a}^{T} \hat{\mathbf{x}}}{\sqrt{2 \mathbf{a}^{T} \Sigma \mathbf{a}}}\right)<br>$$<br>where $\operatorname{erf}(\cdot)$ is standard error function as $\operatorname{erf}(x)=\frac{2}{\sqrt{\pi}}\int_0^x e^{-t^2} dt$.</p>
<p><strong>Lemma 2:</strong></p>
<p>Given a multivariate random variable $\mathbf{x}\sim\mathcal{N}(\hat{\mathbf{x}},\Sigma)$ and a probability threshold $\delta\in(0,0.5)$, then<br>$$<br>\operatorname{Pr}\left(\mathbf{a}^{T} \mathbf{x} \leq b\right) \leq \delta \Longleftrightarrow \mathbf{a}^{T} \hat{\mathbf{x}}-b \geq c<br>$$<br>where $c=\operatorname{erf}^{-1}(1-2 \delta) \sqrt{2 \mathbf{a}^{T} \Sigma \mathbf{a}}$. </p>
<blockquote>
<p>Gaussian distribution:</p>
<ul>
<li>pdf: $f(x|\mu,\sigma^2)=\frac{1}{\sqrt{2\pi \sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$</li>
<li>cdf: $\Phi(x) = \frac{1}{\sqrt{2\pi}} \int\limits_{-\inf}^x e^{- \frac{t^2}{2}} dt$</li>
<li>erf: $\operatorname{erf}(x) = \frac{2}{\sqrt{\pi}} \int\limits_0^x e^{-t^2} dt$   (gives the probability of a random variable with normal distribution of mean 0 and variance 1/2 falling in the range $[-x,x]$)</li>
<li>Gaussian form translation: $f(x|\mu,\sigma^2)=\frac{1}{\sigma} \varphi(\frac{x-\mu}{\sigma})$</li>
</ul>
</blockquote>
</li>
<li><p>Inter-robot Collision Avoidance Constraint</p>
<p>Two robot position $\mathbf{p}<em>{i} \sim \mathcal{N}\left(\hat{\mathbf{p}}</em>{i}, \Sigma_{i}\right)$, $\mathbf{p}<em>{j} \sim \mathcal{N}\left(\hat{\mathbf{p}}</em>{j}, \Sigma_{j}\right)$, the collision probability is<br>$$<br>\operatorname{Pr}\left(\mathbf{x}<em>{i} \in C</em>{i j}\right)=\int_{\mathbb{R}^{3}} I_{C}\left(\mathbf{p}<em>{i}, \mathbf{p}</em>{j}\right) p\left(\mathbf{p}<em>{i}\right) p\left(\mathbf{p}</em>{j}\right) d \mathbf{p}<em>{i} d \mathbf{p}</em>{j}<br>$$<br>where $I_C$ is the indicator function, i.e.,<br>$$<br>I_{C}\left(\mathbf{p}<em>{i}, \mathbf{p}</em>{j}\right)=\left{\begin{array}{ll}{1,} &amp; {\text { if }\left|\mathbf{p}<em>{i}-\mathbf{p}</em>{j}\right| \leq r_{i}+r_{j}} \ {0,} &amp; {\text { otherwise }}\end{array}\right.<br>$$</p>
<p>Assume $\mathbf{p}<em>{i}$ and $\mathbf{p}</em>{j}$ independent. $\mathbf{p}<em>{i}-\mathbf{p}</em>{j}\sim \mathcal{N}\left({\mathbf{p}<em>{i}}-{\mathbf{p}</em>{j}}, \Sigma_{i}-\Sigma_{j} \right)$, so<br>$$<br>\operatorname{Pr}\left(\mathbf{x}<em>{i} \in C</em>{i j}\right)=\int_{\left|\mathbf{p}<em>{i}-\mathbf{p}</em>{j}\right| \leq r_{i}+r_{j}} p\left(\mathbf{p}<em>{i}-\mathbf{p}</em>{j}\right) d\left(\mathbf{p}<em>{i}-\mathbf{p}</em>{j}\right).<br>$$</p>
<p>Here, Collision region is a sphere, and the distribution of $\mathbf{p}_{ij}$ is a ellipsoid. Hard to compute.</p>
<p><strong>Transform the spherical collision region $C_{ij}$ into half space $\tilde{C}_{ij}$</strong><br>$$<br>\tilde{C}<em>{i j} :=\left{\mathbf{x} | \mathbf{a}</em>{i j}^{T}\left(\mathbf{p}<em>{i}-\mathbf{p}</em>{j}\right) \leq b_{i j}\right}<br>$$<br>where $\mathbf{a}<em>{i j}=\left(\hat{\mathbf{p}}</em>{i}-\hat{\mathbf{p}}<em>{j}\right) /\left|\hat{\mathbf{p}}</em>{i}-\hat{\mathbf{p}}<em>{j}\right| \text { and } b</em>{i j}=r_{i}+r_{j}$</p>
<p>Because $C_{ij} \subset \tilde{C}<em>{ij}$, $\operatorname{Pr}\left(\mathbf{x}</em>{i} \in C_{i j}\right) \leq \operatorname{Pr}\left(\mathbf{x}<em>{i} \in \tilde{C}</em>{i j}\right)$. </p>
<p>Based on Lemma 1, <em>an <u>upper bound</em></u> can be obtained:<br>$$<br>\operatorname{Pr}\left(\mathbf{x}<em>{i} \in C</em>{i j}\right) \leq \frac{1}{2}+\frac{1}{2} \operatorname{erf}\left(\frac{b_{i j}-\mathbf{a}<em>{i j}^{T}\left(\hat{\mathbf{p}}</em>{i}-\hat{\mathbf{p}}<em>{j}\right)}{\sqrt{2 \mathbf{a}</em>{i j}^{T}\left(\Sigma_{i}+\Sigma_{j}\right) \mathbf{a}<em>{i j}}}\right)<br>$$<br>Based on Lemma 2, <u><em>transform the chance constraint into deterministic constraint</em></u>:<br>$$<br>\mathbf{a}</em>{i j}^{T}\left(\hat{\mathbf{p}}<em>{i}-\hat{\mathbf{p}}</em>{j}\right)-b_{i j} \geq \operatorname{erf}^{-1}\left(1-2 \delta_{r}\right) \sqrt{2 \mathbf{a}<em>{i j}^{T}\left(\Sigma</em>{i}+\Sigma_{j}\right) \mathbf{a}_{i j}}<br>$$</p>
<img src="http://ww1.sinaimg.cn/large/006y8mN6gy1g6qzx6pvzqj319u0osqh6.jpg" style="zoom:40%"></li>
<li><p>Robot-Obstacle Collision Chance constraint</p>
<p>position of robots and obstacles are independent.<br>$$<br>\operatorname{Pr}\left(\mathbf{x}<em>{i} \in C</em>{i o}\right)=\int_{\left|\mathbf{p}<em>{i}-\mathbf{p}</em>{o}\right|<em>{\Omega</em>{i o}} \leq 1} p\left(\mathbf{p}<em>{i}-\mathbf{p}</em>{o}\right) d\left(\mathbf{p}<em>{i}-\mathbf{p}</em>{o}\right)<br>$$<br>Here, collision region is ellipsoid. </p>
<p><strong>Linearize the collision</strong></p>
<p>Affine coordinate transformation $\tilde{\mathbf{y}}=\Omega_{jo}^{\frac{1}{2}} \mathbf{y}$ to <u><em>transform ellipsoid to unit sphere</em></u> $\tilde{C}_{io}$. Accordingly, the robot and obstacel position need to be transformed into new distribution</p>
<p>$\tilde{\mathbf{p}}<em>{i} \sim \mathcal{N}\left(\hat{\tilde{\mathbf{p}}}</em>{i}, \tilde{\Sigma}<em>{i}\right)$, $\tilde{\mathbf{p}}</em>{o} \sim \mathcal{N}\left(\hat{\mathbf{p}}<em>{o}, \tilde{\Sigma}</em>{o}\right)$, where<br>$$<br>\begin{aligned} \hat{\mathbf{p}}<em>{i}=\Omega</em>{i o}^{\frac{1}{2}} \hat{\mathbf{p}}<em>{i}, &amp; \tilde{\Sigma}</em>{i}=\Omega_{i o}^{\frac{1}{2} T} \Sigma_{i} \Omega_{i o}^{\frac{1}{2}} \ \hat{\hat{\mathbf{p}}}<em>{o}=\Omega</em>{i o}^{\frac{1}{2}} \hat{\mathbf{p}}<em>{o}, &amp; \tilde{\Sigma}</em>{o}=\Omega_{i o}^{\frac{1}{2} T} \Sigma_{o} \Omega_{i o}^{\frac{1}{2}} \end{aligned}<br>$$<br>let $\operatorname{Pr}\left(\tilde{\mathbf{x}}<em>{i} \in \tilde{C}</em>{i o}\right)=\int_{\left|\mathbb{D}<em>{i}-\tilde{\mathbf{p}}</em>{o}\right| \leq 1} p\left(\tilde{\mathbf{p}}<em>{i}-\tilde{\mathbf{p}}</em>{o}\right) d\left(\tilde{\mathbf{p}}<em>{i}-\tilde{\mathbf{p}}</em>{o}\right) $, we have<br>$$<br>\operatorname{Pr}\left(\mathbf{x}<em>{i} \in C</em>{i o}\right)=\operatorname{Pr}\left(\tilde{\mathbf{x}}<em>{i} \in \tilde{C}</em>{i o}\right)<br>$$<br>Use same <u><em>linearization method</em></u> for phere with $\mathbf{a}<em>{i o}=\left(\hat{\mathbf{p}}</em>{i}-\hat{\mathbf{p}}<em>{o}\right) /\left|\hat{\mathbf{p}}</em>{i}-\hat{\mathbf{p}}<em>{o}\right| \text { and } b</em>{i o}=1$.</p>
<p><u><em>Transform into deterministic constraint:</em></u><br>$$<br>\mathbf{a}<em>{i o}^{T} \Omega</em>{i o}^{\frac{1}{2}}\left(\hat{\mathbf{p}}<em>{i}-\hat{\mathbf{p}}</em>{j}\right)- b_{i o} \geq \operatorname{erf}^{-1}\left(1-2 \delta_{o}\right) \cdot \sqrt{2 \mathbf{a}<em>{i o}^{T} \Omega</em>{i o}^{\frac{1}{2}}\left(\Sigma_{i}+\Sigma_{j}\right) \Omega_{i o}^{\frac{1}{2} T} \mathbf{a}_{i o}}<br>$$</p>
<img src="http://ww1.sinaimg.cn/large/006y8mN6gy1g6r0ccv01oj319s0nqgzq.jpg" style="zoom:40%"></li>
</ol>
<h2 id="Deterministic-MPC-Formulation"><a href="#Deterministic-MPC-Formulation" class="headerlink" title="Deterministic MPC Formulation"></a>Deterministic MPC Formulation</h2><h3 id="Deterministic-MPC-formulation"><a href="#Deterministic-MPC-formulation" class="headerlink" title="Deterministic MPC formulation"></a>Deterministic MPC formulation</h3><ul>
<li><p>Cost function</p>
<ul>
<li><p>terminal cost: </p>
</li>
<li><p>stage cost</p>
</li>
<li><p>potential field cost : increase the separation between robots and obstacles<br>$$<br>J_{i, c}^{k}\left(\hat{\mathbf{x}}<em>{i}^{k}\right)=\sum</em>{j \in \mathcal{I} \cup \mathcal{I}<em>{o}, j \neq i}  {J</em>{i, j, c}^{k}(\hat{\mathbf{x}}<em>{i}^{k}})<br>$$<br>With<br>$$<br>J</em>{i, j, c}^{k}\left(\hat{\mathbf{x}}<em>{i}^{k}\right)=<br>\begin{cases}<br>l</em>{i, c}^{k}\left(d_{i j}^{\text {safe }}-d_{i j}\right), &amp; d_{i j}&lt;d_{i j}^{\text {safe }} \<br>0, &amp; d_{i j}\ge d_{i j}^{\text {safe }}<br>\end{cases}<br>$$</p>
</li>
</ul>
</li>
<li><p>Constraints:</p>
<ul>
<li>transformed into deterministic constraints</li>
</ul>
</li>
<li><p>Problem:<br>$$<br>\begin{array}{c}{\min <em>{\hat{\mathbf{x}}</em>{i}^{1 : N}, \mathbf{u}<em>{i}^{0 : N-1}} \quad J</em>{i}^{N}\left(\hat{\mathbf{x}}<em>{i}^{N}\right)+\sum</em>{k=0}^{N-1} J_{i, u}^{k}\left(\mathbf{u}<em>{i}^{k}\right)+\sum</em>{k=1}^{N} J_{i, c}^{k}\left(\hat{\mathbf{x}}<em>{i}^{k}\right)} \ {\text { s.t. } \quad \mathbf{x}</em>{i}^{0}=\hat{\mathbf{x}}<em>{i}(0), \quad \hat{\mathbf{x}}</em>{i}^{k}=\mathbf{f}<em>{i}\left(\hat{\mathbf{x}}</em>{i}^{k-1}, \mathbf{u}<em>{i}^{k-1}\right)} \ {g</em>{i j}^{k}\left(\hat{\mathbf{x}}<em>{i}^{k}, \hat{\mathbf{p}}</em>{j}^{k}, \Sigma_{i}^{k}, \Sigma_{j}^{k}, \delta_{r}\right) \leq 0} \ {g_{i o}^{k}\left(\hat{\mathbf{x}}<em>{i}^{k}, \hat{\mathbf{p}}</em>{o}^{k}, \Sigma_{i}^{k}, \Sigma_{o}^{k}, \delta_{o}\right) \leq 0} \ {\mathbf{u}<em>{i}^{k-1} \in \mathcal{U}</em>{i}, \quad \hat{\mathbf{x}}<em>{i}^{k} \in \mathcal{X}</em>{i}} \ {\forall j \neq i \in \mathcal{I} ; \forall o \in \mathcal{I}<em>{o} ; \forall k \in{1, \ldots, N}}\end{array}<br>$$<br>where $g</em>{ij}$ and $g_{io}$ are deterministic constraints.</p>
</li>
</ul>
<h3 id="How-to-obtain-the-mean-and-covariance-of-position"><a href="#How-to-obtain-the-mean-and-covariance-of-position" class="headerlink" title="How to obtain the mean and covariance of position"></a>How to obtain the mean and covariance of position</h3><ol>
<li>Constant velocity model without communication</li>
<li>Sequential Planning with communication</li>
<li>Distributed planning with communication</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhang-xiaoxue.github.io/2020/06/30/Chance%20Constraints/Chance-constrained%20add%20velocity%20obstacles/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/photo_blue.jpg">
      <meta itemprop="name" content="Xiaoxue Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiaoxue Zhang - NUS">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/06/30/Chance%20Constraints/Chance-constrained%20add%20velocity%20obstacles/" class="post-title-link" itemprop="url">Chance-constrained ADD Velocity Obstacles</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-06-30 12:00:00" itemprop="dateCreated datePublished" datetime="2020-06-30T12:00:00+08:00">2020-06-30</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2021-08-16 15:07:29" itemprop="dateModified" datetime="2021-08-16T15:07:29+08:00">2021-08-16</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Chance-Constraints/" itemprop="url" rel="index"><span itemprop="name">Chance Constraints</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Chance-constrained-Velocity-Obstacles"><a href="#Chance-constrained-Velocity-Obstacles" class="headerlink" title="Chance-constrained + Velocity Obstacles"></a>Chance-constrained + Velocity Obstacles</h1><h2 id="Model"><a href="#Model" class="headerlink" title="Model:"></a>Model:</h2><ol>
<li><p>Original robot model:<br>$$<br>\dot{x}=f(x)+B u<br>$$<br>In detail,<br>$$<br>\begin{equation}<br>\label{eq:model}<br>\begin{bmatrix} {\dot{p}} \ {\dot{v}} \ {\dot{\zeta}} \ {\dot{\omega}}\end{bmatrix} =<br>\begin{bmatrix} {R(\phi, \theta, \psi)}^\top {v} \ {-{\omega}\times v + g {R(\phi, \theta, \psi)} e} \ W(\phi, \theta, \psi) {\omega} \ J^{-1}(-{\omega} \times J {\omega}) \end{bmatrix} + B {(u_{eq} + \delta u)}. \<br>\end{equation}<br>$$<br>with  ${e}=[0,0,1]^\top$,<br>$$<br>{R}(\phi, \theta, \psi)=<br>\begin{bmatrix}<br>{c\theta c\psi} &amp; {c\theta s\psi} &amp; {-s\theta} \<br>{s\theta c\psi s\phi-s\psi c\phi} &amp; {s\theta s\psi s\phi+c\psi c\phi} &amp; {c\theta s\phi} \<br>{s\theta c\psi c\phi+s\psi s\phi} &amp; {s\theta s\psi c\phi-c\psi s\phi} &amp; {c\theta c\phi}<br>\end{bmatrix}.<br>$$<br>and<br>$$<br>\begin{equation*}<br>W(\phi, \theta, \psi)=\begin{bmatrix}{1} &amp; {s\phi t\theta} &amp; {c\phi t\theta} \ {0} &amp; {c\phi} &amp; {-s\phi} \ {0} &amp; {s\phi sc\theta} &amp; {c\phi sc\theta}\end{bmatrix}.<br>\end{equation*}<br>$$</p>
</li>
<li><p>Stochastic Robot model:</p>
<p>Model each robot as enclosing rigid sphere $S_i$ with radius $r_i$, $i$ means the index of robots $i\in{1, 2, \cdots,n}$.<br>$$<br>x_i^{k+1}=f_i(x_i^{k})+B u_i^{k} + \omega_i^k, \quad x_i^k \sim \mathcal{N}(\hat{x}_i^0,\Gamma_i^0), \quad \omega_i^k\sim\mathcal{N}(0,Q_i^k)<br>$$<br>Mean $\hat{x}_i^0$ and covariance $\Gamma_i^0$  of initial state can be estimated by UKF. State $x_i^k = [(p_i^k)^\top, (v_i^k)^\top, (\zeta_i^k)^\top, (\omega_i^k)^\top ]^\top.$ </p>
</li>
<li><p>Moving Obstacle model:</p>
<p>obstacle $o \in {1, 2, \cdots, m}$ at position $p_o$, modelling it as non-rotating ellipsoid $S_o$ with semi-principal axes $(a_0,b_0,c_0)$ and rotation matrix $R_o$.</p>
<p>Constant velocity with noise $\omega_o(t)\sim\mathcal{N}(0, Q_o(t))$, i.e., $\dot{p}_o(t)=\omega_o(t)$.</p>
<p>predict its future position using KF.</p>
</li>
</ol>
<blockquote>
<p>Velocity Obstacles:</p>
<ul>
<li><p>robot $B_i$ is circle, center $c_i$, radius $r_i$, velocity $v_i=\dot{c}_i$</p>
</li>
<li><p>robot $B_j$ is circle, center $c_j$, radius $r_j$, velocity $v_j = \dot{c}_j$</p>
</li>
<li><p>relative velocity $v_{ij} = v_i - v_j$</p>
</li>
<li><p>Collision region:<br>$$<br>B_{ij} = { c_j + r: r\in R^2, |r| \leq r_i+r_j }<br>$$</p>
<p>$$<br>\lambda_{ij}(v_{ij}) = {c_i+\mu v_{ij}: \mu\geq0}<br>$$</p>
<p>Collision occurs iff $B_{ij}\cap \lambda_{ij}(v_{ij}) \ne \empty$</p>
</li>
<li><p>Collision cone $CC_{ij}$<br>$$<br>CC_{ij} = { v_{ij}:B_{ij}\cap\lambda_{ij}(v_{ij})\neq \empty }<br>$$</p>
</li>
<li><p>Velocity Obstacle $VO_{ij}$<br>$$<br>VO_{ij} = { v_i: (v_i-v_j)\in CC_{ij} }<br>$$<br>i.e., $VO_{ij} = v_j + CC_{ij}$</p>
<p>Now, for $B_i$, any velocity $v_i\in VO_{ij}$ will lead to collision.</p>
</li>
<li><p>Composite velocity obstacle for $B={B_1, \cdots, B_n}$<br>$$<br>VO_i=\cup_{j\ne i} VO_{ij}<br>$$</p>
</li>
</ul>
<img src="https://raw.githubusercontent.com/Lisnol1/PicGo--/master/20190909224723.png" style="zoom:40%">
</blockquote>
<blockquote>
<p>Probabilistic Velocity Obstacles</p>
<ul>
<li>uncertainty of shape and velocity</li>
</ul>
<ol>
<li><p>Shape uncertainty</p>
<p>probabilistic collision cone : $PCC_{ij}: \mathbb{R}^2 \rightarrow [0,1]$</p>
<img src="https://raw.githubusercontent.com/Lisnol1/PicGo--/master/20190919153636.png" style="zoom: 30%"></li>
<li><p>Velocity Uncerinty</p>
<p>pdf of velocity of $B_{j}$ : $V_j: \mathbb{R}^2 \rightarrow \mathbb{R}_0^+$</p>
</li>
</ol>
<p>==Probabilistic velocity obstacles==: $PVO_{ij}: \mathbb{R}^2 \rightarrow [0,1]$<br>$$<br>PVO_{ij} (v_i) = \int\limits_{R^2} V_j(v_j) \  PCC_{ij}(v_i-v_j) \ d^2v_j<br>$$<br>which is equivalent to<br>$$<br>PVO_{ij} (v_i) = V_j * \ PCC_{ij} \quad \text{convolution of two function}<br>$$<br>Composite Probabilistic Velocity Obstacle<br>$$<br>PVO_i = 1 - \prod\limits_{j\neq i} \left(1-PVO_{ij}\right)<br>$$<br>==Navigation:==</p>
<p>$U_i : \mathbb{R}^2 \rightarrow [0,1]$ : utility of velocities $v_i$ for the motion goal of $B_i$. Full utility of $v_i$ is only attained if (1) $v_i$ is dynamically reachable (2) $v_i$ is collision free. </p>
<p>relative utility function:<br>$$<br>RU_i = U_i \cdot D_i \cdot (1-PVO_i)<br>$$<br>$D_i : \mathbb{R}^2 \rightarrow [0,1]$ means  reachability of a new velocity. </p>
<p>Repeatedly choose a velocity $v_i$ which maximizes the relative utility $RU_i$.</p>
</blockquote>
<blockquote>
</blockquote>
<ol start="4">
<li><p>Collision  Chance Constraints:</p>
<img src="https://raw.githubusercontent.com/Lisnol1/PicGo--/master/3D_CCP.jpg">

<p>robot $i$: position $p_i$, velocity $v_i$</p>
<p>robot $j$: position $p_j$, velocity $v_j$</p>
<ol>
<li>Collision Condition:<br>$$<br>C_{ij}^k := { v_i^k \lvert | v_i^k-v_j^k |  }<br>$$</li>
</ol>
</li>
</ol>
<p>$$<br>\mathbf{x}<em>{i}^{k+1}=\mathbf{f}</em>{i}\left(\mathbf{x}<em>{i}^{k}, \mathbf{u}</em>{i}^{k}\right)+\omega_{i}^{k}, \quad \mathbf{x}<em>{i}^{0} \sim \mathcal{N}\left(\hat{\mathbf{x}}</em>{i}^{0}, \Gamma_{i}^{0}\right),\quad \omega_i^k\sim\mathcal{N}(0,Q_i^k)<br>$$<br>where $\mathbf{x}<em>{i}^{k}=\left[\mathbf{p}</em>{i}^{k}, \mathbf{v}<em>{i}^{k}, \phi</em>{i}^{k}, \theta_{i}^{k}, \psi_{i}^{k}\right]^{T} \in \mathcal{X}<em>{i} \subset \mathbb{R}^{n</em>{x}}$, the mean and covariance of initial state $\mathbf{x}_i^0$ are obtained by state estimator (UKF). </p>
<ol>
<li><p>Obstacle model:</p>
<p>$o\in \mathcal{I}_0={1,2,\cdots,n_0} \subset \mathbb{N}$ at position $\mathbf{p}_o \in \mathbb{R}^3$, can be represented by <em>ellipsoid</em> $S_0$ with semi-principal axes $(a_0,b_o,c_o)$ and rotation matrix $R_o$. </p>
<p>moving obstacles has constant velocity with Guassian noise $\omega_o(t)\sim\mathcal{N}(0,Q_o(t))$ in aaceleration, i.e. $\ddot{\mathbf{p}}_o=\omega_o(t)$. estimate and predict the future position and uncertainty by linear KF.</p>
</li>
<li><p>Collision Chance Constraints:</p>
<ol>
<li><p>Collision condition:</p>
<ul>
<li><p>collision of robot $i$ with robot $j$<br>$$<br>C_{i j}^{k} :=\left{\mathbf{x}<em>{i}^{k} |\left|\mathbf{p}</em>{i}^{k}-\mathbf{p}<em>{j}^{k}\right| \leq r</em>{i}+r_{j}\right}<br>$$</p>
</li>
<li><p>collision of robot $i$ with obstacle $o$:</p>
<p>obstacle: enlarged ellipsoid and check if the robot is inside it.<br>$$<br>C_{i o}^{k} :=\left{\mathbf{x}<em>{i}^{k} |\left|\mathbf{p}</em>{i}^{k}-\mathbf{p}<em>{o}^{k}\right|</em>{\Omega_{i o}} \leq 1\right},\quad<br>\Omega_{i o}=R_{o}^{T} \operatorname{diag}\left(1 /\left(a_{o}+r_{i}\right)^{2}, 1 /\left(b_{o}+r_{i}\right)^{2}, 1 /\left(c_{o}+r_{i}\right)^{2}\right) {R_{o}}<br>$$</p>
</li>
</ul>
</li>
<li><p>Chance constraints:<br>$$<br>\begin{array}{ll}{\operatorname{Pr}\left(\mathbf{x}<em>{i}^{k} \notin C</em>{i j}^{k}\right) \geq 1-\delta_{r},} &amp; {\forall j \in \mathcal{I}, j \neq i} \ {\operatorname{Pr}\left(\mathbf{x}<em>{i}^{k} \notin C</em>{i o}^{k}\right) \geq 1-\delta_{o},} &amp; {\forall o \in \mathcal{I}_{o}}\end{array}<br>$$</p>
</li>
</ol>
</li>
<li><p>Problem Formulation: </p>
<p>optimiation problem with $N$ time steps and planning horizon $\tau=N\Delta t$, $\Delta t$ is time step.<br>$$<br>\begin{aligned} \min <em>{\hat{x}</em>{i}^{1}, \cdots, u_{i}^{0}, N-1} \quad &amp; \sum_{k=0}^{N-1} J_{i}^{k}\left(\hat{\mathbf{x}}<em>{i}^{k}, \mathbf{u}</em>{i}^{k}\right)+J_{i}^{N}\left(\hat{\mathbf{x}}<em>{i}^{N}\right) \ \text { s.t. }\quad &amp; \mathbf{x}</em>{i}^{0}=\hat{\mathbf{x}}<em>{i}(0), \quad \hat{\mathbf{x}}</em>{i}^{k}=\mathbf{f}<em>{i}\left(\hat{\mathbf{x}}</em>{i}^{k-1}, \mathbf{u}<em>{i}^{k-1}\right) \ &amp; \operatorname{Pr}\left(\mathbf{x}</em>{i}^{k} \notin C_{i j}^{k}\right) \geq 1-\delta_{r}, \forall j \in \mathcal{I}, j \neq i \ &amp; \operatorname{Pr}\left(\mathbf{x}<em>{i}^{k} \notin C</em>{i o}^{k}\right) \geq 1-\delta_{o}, \forall o \in \mathcal{I}<em>{o} \ &amp; \mathbf{u}</em>{i}^{k-1} \in \mathcal{U}<em>{i}, \quad \hat{\mathbf{x}}</em>{i}^{k} \in \mathcal{X}_{i} \ &amp; \forall k \in{1, \ldots, N} \end{aligned}<br>$$</p>
</li>
<li></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhang-xiaoxue.github.io/2020/06/30/Machine%20Learning/introduction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/photo_blue.jpg">
      <meta itemprop="name" content="Xiaoxue Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xiaoxue Zhang - NUS">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/06/30/Machine%20Learning/introduction/" class="post-title-link" itemprop="url">Machine Learning (Lee Hongyi)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-06-30 12:00:00" itemprop="dateCreated datePublished" datetime="2020-06-30T12:00:00+08:00">2020-06-30</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2021-08-16 15:10:40" itemprop="dateModified" datetime="2021-08-16T15:10:40+08:00">2021-08-16</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="ML-framework"><a href="#ML-framework" class="headerlink" title="ML framework:"></a>ML framework:</h1><img src="https://raw.githubusercontent.com/Lisnol1/CloudIMG/master/20210314220741.png" style="zoom:90">

<h2 id="1-Function-with-unknown-y-f-theta-x"><a href="#1-Function-with-unknown-y-f-theta-x" class="headerlink" title="1. Function with unknown $y=f_\theta(x)$"></a>1. Function with unknown $y=f_\theta(x)$</h2><p>Model bias: </p>
<p>Approximate continuous curve by a piecewise linear cure. In order to have good approximation, we need sufficient <strong>pieces (basic components of the piecewise linear curve)</strong>.</p>
<blockquote>
<p> sigmoid: $y(x;c,b,w)=c\frac{1}{1+e^{-(b+wx)}}$</p>
</blockquote>
<p>How to reduce the model bias:</p>
<ol>
<li>more flexible model</li>
<li>more feature</li>
</ol>
<img src="https://raw.githubusercontent.com/Lisnol1/CloudIMG/master/20210314220212.png" style="zoom:90">

<ul>
<li>In ML, the pieces (activation function) can be sigmoid function, hard sigmoid, ReLU, etc. </li>
<li>number of hidden layer</li>
</ul>
<h2 id="2-Define-Loss-L-theta"><a href="#2-Define-Loss-L-theta" class="headerlink" title="2. Define Loss $L(\theta)$"></a>2. Define Loss $L(\theta)$</h2><p>Loss: function of parameters to evaluate how good of the set of parameters $L=\frac{1}{N} \sum_n e_n$.</p>
<p>MAE, MSE, cross-entropy</p>
<p>cross-entropy: $e=-\sum_i \hat y_i \ln y_i’$ 其中， [$\hat y$ is label]</p>
<blockquote>
<p>minimize cross-entropy is equivalent to maximizing likelihood.</p>
</blockquote>
<img src="https://raw.githubusercontent.com/Lisnol1/CloudIMG/master/20210326145149.png" width="400">

<h2 id="3-Optimization-theta-operatorname-argmin-theta-L"><a href="#3-Optimization-theta-operatorname-argmin-theta-L" class="headerlink" title="3. Optimization: $\theta^* = \operatorname{argmin}_\theta L$"></a>3. Optimization: $\theta^* = \operatorname{argmin}_\theta L$</h2><p><strong>Gradient descent:</strong></p>
<p><img src="https://raw.githubusercontent.com/Lisnol1/CloudIMG/master/20210314221227.png" width="450">  <img src="https://raw.githubusercontent.com/Lisnol1/CloudIMG/master/20210314221729.png" width="450"></p>
<p>1个epoch之后，shuffle，改变batch</p>
<p><strong>small batch v.s. large batch:</strong></p>
<ul>
<li><p>large batch (not too large) will not cost much time thanks to the GPU parallel computation. So, it will be efficient for one epoch</p>
</li>
<li><p>then small batch will cost much time for one epoch. It will result in noisy direction, which will be better in some cases.</p>
</li>
<li><p>large batch and small batch work well in training, but small batch works worse in testing – overfitting. </p>
</li>
<li><p>large batch and small batch work well in training, but large batch works worse in testing – NOT overfitting, 是因为optimization </p>
<p><img src="https://raw.githubusercontent.com/Lisnol1/CloudIMG/master/20210326115342.png" width="250"> <img src="https://raw.githubusercontent.com/Lisnol1/CloudIMG/master/20210326115958.png" width="250"> <img src="https://raw.githubusercontent.com/Lisnol1/CloudIMG/master/20210326120055.png" width="270"> </p>
</li>
</ul>
<p><strong>Momentum</strong> [Consider direction]</p>
<p>Movement of last step - gradient at present</p>
<p><img src="https://raw.githubusercontent.com/Lisnol1/CloudIMG/master/20210326120906.png" width="400"> <img src="https://raw.githubusercontent.com/Lisnol1/CloudIMG/master/20210326121154.png" width="400"></p>
<p>$m_i$ is the weighted sum of all the previous gradient $g^0, g^1, \cdots, g^{i-1}$.</p>
<p><strong>Adaptive learning rate</strong> [Consider magnitude]</p>
<p>gradient 变化率小，选用大的learning rate；gradient 变化率大，选用小的learning rate。</p>
<ul>
<li>Adagrad</li>
</ul>
<p><img src="https://raw.githubusercontent.com/Lisnol1/CloudIMG/master/20210326122244.png" width="270"> <img src="https://raw.githubusercontent.com/Lisnol1/CloudIMG/master/20210326122540.png" width="270"> <img src="https://raw.githubusercontent.com/Lisnol1/CloudIMG/master/20210326122802.png" width="270"> </p>
<ul>
<li>RMSProp</li>
</ul>
<p><img src="https://raw.githubusercontent.com/Lisnol1/CloudIMG/master/20210326123203.png" width="270"> <img src="https://raw.githubusercontent.com/Lisnol1/CloudIMG/master/20210326123405.png" width="270"></p>
<p><strong>Adam: RMSProp + Momentum</strong></p>
<p><strong>Learning rate scheduling</strong></p>
<ul>
<li>learning rate decay: As the time goes, we are closer to the destination, so we reduce the learning rate</li>
<li>warm up: increase first and then decrease (at the beginning, the estimate of $\sigma_i^t$ has large variance) [RAdam]</li>
</ul>
<h1 id="Problem"><a href="#Problem" class="headerlink" title="Problem:"></a>Problem:</h1><p>overfitting</p>
<h2 id="Methods-to-improve"><a href="#Methods-to-improve" class="headerlink" title="Methods to improve:"></a>Methods to improve:</h2><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1gojw3kx441j21240swh04.jpg" style="zoom:99"> 

<p><strong>reason of large loss on training data:</strong></p>
<ol>
<li>Model bias: model is too simple. –&gt; redesign more flexible model (more feature; more neutrons layers)</li>
<li>Optimization: local minima</li>
</ol>
<p><strong>How to know which reason leads to the large loss on training data:</strong></p>
<p>If deeper network has larger loss on training data, there might be optimization issue. </p>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1gojwbce2f9j212m0pyqfk.jpg" width="400"> <img src="https://tva1.sinaimg.cn/large/e6c9d24egy1gojweeh4ycj210u0q6alk.jpg" width="400"></p>
<p><strong>Overfitting:</strong></p>
<p>Smaller loss on training data, and larger loss on testing data.</p>
<p>Solution: </p>
<ol>
<li>more training data; </li>
<li>Data augmentation (reasonable);</li>
<li>constrained model <ul>
<li>less parameters, sharing parameters [e.g. CNN which is constrained one compared with fully-connected NN]</li>
<li>Less features</li>
<li>early stopping</li>
<li>regularization</li>
<li>Dropout</li>
</ul>
</li>
</ol>
<p>But if give more constraints on model, –&gt; Bias-complexity trade-off [cross validation, N-fold cross validation]</p>
<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1gojwvcbkv6j20xo0obwm6.jpg" style="zoom:99">



<img src="https://raw.githubusercontent.com/Lisnol1/CloudIMG/master/20210320131017.png" width="400">

<p>critical point: gradient  = 0</p>
<p><img src="https://raw.githubusercontent.com/Lisnol1/CloudIMG/master/20210320131335.png" width="300"> <img src="https://raw.githubusercontent.com/Lisnol1/CloudIMG/master/20210320131445.png" width="300"> <img src="https://raw.githubusercontent.com/Lisnol1/CloudIMG/master/20210320132055.png" width="300"></p>
<ul>
<li>把data的loss写出来，求loss对每个参数的偏导，令其=0， 检测其Hessian</li>
</ul>
<p><strong>How to avoid critical point ?</strong></p>
<ul>
<li><p>Avoid saddle point</p>
<img src="https://raw.githubusercontent.com/Lisnol1/CloudIMG/master/20210320141142.png" width="400">

<p>Based on eigenvector and eigenvalue of Hessian, we can update the parameter along the direction of the eigenvector –&gt; reduce loss.</p>
</li>
<li><p>If enough more parameter, the error surface will be more complex. But the local minima will be degrade to saddle point. [local minima in low dimension –&gt; saddle point in higher dimension]. </p>
<img src="https://raw.githubusercontent.com/Lisnol1/CloudIMG/master/20210320142402.png" width="400"></li>
</ul>
<img src="https://raw.githubusercontent.com/Lisnol1/CloudIMG/master/20210320142522.png" width="400">


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>
<script src="/js/comments.js"></script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Xiaoxue Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div><script color="0,0,255" opacity="0.5" zIndex="-1" count="199" src="https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js"></script>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{&quot;enable&quot;:true,&quot;tags&quot;:&quot;none&quot;,&quot;single_dollars&quot;:true,&quot;cjk_width&quot;:0.9,&quot;normal_width&quot;:0.6,&quot;append_css&quot;:true,&quot;js&quot;:&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;mathjax@3.1.4&#x2F;es5&#x2F;tex-mml-chtml.js&quot;}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
